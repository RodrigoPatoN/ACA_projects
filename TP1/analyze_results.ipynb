{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_epochs</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>n_layers</th>\n",
       "      <th>activation_function</th>\n",
       "      <th>loss_function</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>Cross Entropy</td>\n",
       "      <td>ADAM</td>\n",
       "      <td>[{'loss_values': [232.88340389728546, 219.4525...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>Cross Entropy</td>\n",
       "      <td>SGD</td>\n",
       "      <td>[{'loss_values': [239.34742295742035, 239.1654...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>Cross Entropy</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>[{'loss_values': [1311.3456435203552, 228.9097...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>Multi Margin</td>\n",
       "      <td>ADAM</td>\n",
       "      <td>[{'loss_values': [90.5774205327034, 81.7014083...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>Multi Margin</td>\n",
       "      <td>SGD</td>\n",
       "      <td>[{'loss_values': [105.32916295528412, 105.0802...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>50</td>\n",
       "      <td>64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>Cross Entropy</td>\n",
       "      <td>SGD</td>\n",
       "      <td>[{'loss_values': [164.53463542461395, 124.4378...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>50</td>\n",
       "      <td>64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>Cross Entropy</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>[{'loss_values': [12514.1414488554, 5595.03428...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>50</td>\n",
       "      <td>64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>Multi Margin</td>\n",
       "      <td>ADAM</td>\n",
       "      <td>[{'loss_values': [504.3324379324913, 226.14446...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>50</td>\n",
       "      <td>64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>Multi Margin</td>\n",
       "      <td>SGD</td>\n",
       "      <td>[{'loss_values': [67.28866493701935, 59.539265...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>50</td>\n",
       "      <td>64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>Multi Margin</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>[{'loss_values': [2768.8179498314857, 1365.907...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_epochs batch_size learning_rate n_layers activation_function  \\\n",
       "0         50         32         0.001        3                relu   \n",
       "1         50         32         0.001        3                relu   \n",
       "2         50         32         0.001        3                relu   \n",
       "3         50         32         0.001        3                relu   \n",
       "4         50         32         0.001        3                relu   \n",
       "..       ...        ...           ...      ...                 ...   \n",
       "139       50         64           0.1       15             sigmoid   \n",
       "140       50         64           0.1       15             sigmoid   \n",
       "141       50         64           0.1       15             sigmoid   \n",
       "142       50         64           0.1       15             sigmoid   \n",
       "143       50         64           0.1       15             sigmoid   \n",
       "\n",
       "     loss_function optimizer  \\\n",
       "0    Cross Entropy      ADAM   \n",
       "1    Cross Entropy       SGD   \n",
       "2    Cross Entropy   RMSprop   \n",
       "3     Multi Margin      ADAM   \n",
       "4     Multi Margin       SGD   \n",
       "..             ...       ...   \n",
       "139  Cross Entropy       SGD   \n",
       "140  Cross Entropy   RMSprop   \n",
       "141   Multi Margin      ADAM   \n",
       "142   Multi Margin       SGD   \n",
       "143   Multi Margin   RMSprop   \n",
       "\n",
       "                                               results  \n",
       "0    [{'loss_values': [232.88340389728546, 219.4525...  \n",
       "1    [{'loss_values': [239.34742295742035, 239.1654...  \n",
       "2    [{'loss_values': [1311.3456435203552, 228.9097...  \n",
       "3    [{'loss_values': [90.5774205327034, 81.7014083...  \n",
       "4    [{'loss_values': [105.32916295528412, 105.0802...  \n",
       "..                                                 ...  \n",
       "139  [{'loss_values': [164.53463542461395, 124.4378...  \n",
       "140  [{'loss_values': [12514.1414488554, 5595.03428...  \n",
       "141  [{'loss_values': [504.3324379324913, 226.14446...  \n",
       "142  [{'loss_values': [67.28866493701935, 59.539265...  \n",
       "143  [{'loss_values': [2768.8179498314857, 1365.907...  \n",
       "\n",
       "[144 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dnn = pd.read_json('results.json').T\n",
    "\n",
    "data_dnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>recall_train</th>\n",
       "      <th>recall_test</th>\n",
       "      <th>averaged_recall_train</th>\n",
       "      <th>averaged_recall_test</th>\n",
       "      <th>precision_train</th>\n",
       "      <th>precision_test</th>\n",
       "      <th>averaged_precision_train</th>\n",
       "      <th>averaged_precision_test</th>\n",
       "      <th>f1_train_average</th>\n",
       "      <th>f1_test_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.492194</td>\n",
       "      <td>0.452449</td>\n",
       "      <td>[0.45666576580645024, 0.2781380793631726, 0.41...</td>\n",
       "      <td>[0.39492310575368617, 0.26124302397151344, 0.3...</td>\n",
       "      <td>0.492041</td>\n",
       "      <td>0.453465</td>\n",
       "      <td>[0.3923431594126644, 0.4582671777499705, 0.382...</td>\n",
       "      <td>[0.35207534729986034, 0.3796717171717171, 0.35...</td>\n",
       "      <td>0.508026</td>\n",
       "      <td>0.459296</td>\n",
       "      <td>0.499906</td>\n",
       "      <td>0.456362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.289694</td>\n",
       "      <td>0.276531</td>\n",
       "      <td>[0.10461486097624861, 0.535960678336236, 0.091...</td>\n",
       "      <td>[0.0926535974196895, 0.540545522099994, 0.0831...</td>\n",
       "      <td>0.288489</td>\n",
       "      <td>0.281088</td>\n",
       "      <td>[0.2850857940170572, 0.2471789073476965, 0.233...</td>\n",
       "      <td>[0.4244749380598437, 0.24591828080953, 0.17545...</td>\n",
       "      <td>0.330505</td>\n",
       "      <td>0.328967</td>\n",
       "      <td>0.308071</td>\n",
       "      <td>0.303149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.469490</td>\n",
       "      <td>0.425714</td>\n",
       "      <td>[0.22926222423077203, 0.2317780149045233, 0.46...</td>\n",
       "      <td>[0.17854807761175776, 0.18497423247048367, 0.4...</td>\n",
       "      <td>0.469501</td>\n",
       "      <td>0.425392</td>\n",
       "      <td>[0.4713139798855225, 0.4143381572073497, 0.313...</td>\n",
       "      <td>[0.35781766024912004, 0.3630360986918364, 0.29...</td>\n",
       "      <td>0.492767</td>\n",
       "      <td>0.439270</td>\n",
       "      <td>0.480853</td>\n",
       "      <td>0.432220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.500663</td>\n",
       "      <td>0.470204</td>\n",
       "      <td>[0.42116714317564297, 0.3971881422840021, 0.37...</td>\n",
       "      <td>[0.3596384879068333, 0.3887226116726817, 0.346...</td>\n",
       "      <td>0.501354</td>\n",
       "      <td>0.467065</td>\n",
       "      <td>[0.40255447100242014, 0.397145191949951, 0.459...</td>\n",
       "      <td>[0.3486435172522411, 0.38564581583879814, 0.41...</td>\n",
       "      <td>0.520917</td>\n",
       "      <td>0.484875</td>\n",
       "      <td>0.510949</td>\n",
       "      <td>0.475803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.273878</td>\n",
       "      <td>0.260612</td>\n",
       "      <td>[0.12795219917516099, 0.6912996932283679, 0.17...</td>\n",
       "      <td>[0.12190061903965199, 0.6954819776464157, 0.16...</td>\n",
       "      <td>0.271799</td>\n",
       "      <td>0.268520</td>\n",
       "      <td>[0.22030669708290626, 0.2214708161247449, 0.13...</td>\n",
       "      <td>[0.10364346128822381, 0.22680118760984924, 0.1...</td>\n",
       "      <td>0.297552</td>\n",
       "      <td>0.239952</td>\n",
       "      <td>0.284093</td>\n",
       "      <td>0.253433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>139</td>\n",
       "      <td>0.143418</td>\n",
       "      <td>0.140612</td>\n",
       "      <td>[0.2, 0.0, 0.0, 0.0, 0.0, 0.8, 0.0]</td>\n",
       "      <td>[0.2, 0.0, 0.0, 0.0, 0.0, 0.8, 0.0]</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>[0.028775510204081634, 0.0, 0.0, 0.0, 0.0, 0.1...</td>\n",
       "      <td>[0.027755102040816326, 0.0, 0.0, 0.0, 0.0, 0.1...</td>\n",
       "      <td>0.020488</td>\n",
       "      <td>0.020087</td>\n",
       "      <td>0.035837</td>\n",
       "      <td>0.035222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>140</td>\n",
       "      <td>0.143265</td>\n",
       "      <td>0.141224</td>\n",
       "      <td>[0.2, 0.2, 0.0, 0.2, 0.0, 0.4, 0.0]</td>\n",
       "      <td>[0.2, 0.2, 0.0, 0.2, 0.0, 0.4, 0.0]</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>[0.028775510204081634, 0.02811224489795918, 0....</td>\n",
       "      <td>[0.027755102040816326, 0.03040816326530612, 0....</td>\n",
       "      <td>0.020466</td>\n",
       "      <td>0.020175</td>\n",
       "      <td>0.035804</td>\n",
       "      <td>0.035357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>141</td>\n",
       "      <td>0.141837</td>\n",
       "      <td>0.146939</td>\n",
       "      <td>[0.0, 0.2, 0.2, 0.0, 0.2, 0.2, 0.2]</td>\n",
       "      <td>[0.0, 0.2, 0.2, 0.0, 0.2, 0.2, 0.2]</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>[0.0, 0.02857142857142857, 0.02806122448979591...</td>\n",
       "      <td>[0.0, 0.02857142857142857, 0.03061224489795918...</td>\n",
       "      <td>0.020262</td>\n",
       "      <td>0.020991</td>\n",
       "      <td>0.035491</td>\n",
       "      <td>0.036604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>142</td>\n",
       "      <td>0.146122</td>\n",
       "      <td>0.129796</td>\n",
       "      <td>[0.2, 0.2, 0.2, 0.0, 0.2, 0.2, 0.0]</td>\n",
       "      <td>[0.2, 0.2, 0.2, 0.0, 0.2, 0.2, 0.0]</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>[0.028775510204081634, 0.028520408163265305, 0...</td>\n",
       "      <td>[0.027755102040816326, 0.028775510204081634, 0...</td>\n",
       "      <td>0.020875</td>\n",
       "      <td>0.018542</td>\n",
       "      <td>0.036427</td>\n",
       "      <td>0.032824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>143</td>\n",
       "      <td>0.142653</td>\n",
       "      <td>0.143673</td>\n",
       "      <td>[0.2, 0.0, 0.0, 0.0, 0.4, 0.4, 0.0]</td>\n",
       "      <td>[0.2, 0.0, 0.0, 0.0, 0.4, 0.4, 0.0]</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>[0.028775510204081634, 0.0, 0.0, 0.0, 0.057602...</td>\n",
       "      <td>[0.027755102040816326, 0.0, 0.0, 0.0, 0.055306...</td>\n",
       "      <td>0.020379</td>\n",
       "      <td>0.020525</td>\n",
       "      <td>0.035670</td>\n",
       "      <td>0.035893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     iteration  accuracy_train  accuracy_test  \\\n",
       "0            0        0.492194       0.452449   \n",
       "1            1        0.289694       0.276531   \n",
       "2            2        0.469490       0.425714   \n",
       "3            3        0.500663       0.470204   \n",
       "4            4        0.273878       0.260612   \n",
       "..         ...             ...            ...   \n",
       "139        139        0.143418       0.140612   \n",
       "140        140        0.143265       0.141224   \n",
       "141        141        0.141837       0.146939   \n",
       "142        142        0.146122       0.129796   \n",
       "143        143        0.142653       0.143673   \n",
       "\n",
       "                                          recall_train  \\\n",
       "0    [0.45666576580645024, 0.2781380793631726, 0.41...   \n",
       "1    [0.10461486097624861, 0.535960678336236, 0.091...   \n",
       "2    [0.22926222423077203, 0.2317780149045233, 0.46...   \n",
       "3    [0.42116714317564297, 0.3971881422840021, 0.37...   \n",
       "4    [0.12795219917516099, 0.6912996932283679, 0.17...   \n",
       "..                                                 ...   \n",
       "139                [0.2, 0.0, 0.0, 0.0, 0.0, 0.8, 0.0]   \n",
       "140                [0.2, 0.2, 0.0, 0.2, 0.0, 0.4, 0.0]   \n",
       "141                [0.0, 0.2, 0.2, 0.0, 0.2, 0.2, 0.2]   \n",
       "142                [0.2, 0.2, 0.2, 0.0, 0.2, 0.2, 0.0]   \n",
       "143                [0.2, 0.0, 0.0, 0.0, 0.4, 0.4, 0.0]   \n",
       "\n",
       "                                           recall_test  averaged_recall_train  \\\n",
       "0    [0.39492310575368617, 0.26124302397151344, 0.3...               0.492041   \n",
       "1    [0.0926535974196895, 0.540545522099994, 0.0831...               0.288489   \n",
       "2    [0.17854807761175776, 0.18497423247048367, 0.4...               0.469501   \n",
       "3    [0.3596384879068333, 0.3887226116726817, 0.346...               0.501354   \n",
       "4    [0.12190061903965199, 0.6954819776464157, 0.16...               0.271799   \n",
       "..                                                 ...                    ...   \n",
       "139                [0.2, 0.0, 0.0, 0.0, 0.0, 0.8, 0.0]               0.142857   \n",
       "140                [0.2, 0.2, 0.0, 0.2, 0.0, 0.4, 0.0]               0.142857   \n",
       "141                [0.0, 0.2, 0.2, 0.0, 0.2, 0.2, 0.2]               0.142857   \n",
       "142                [0.2, 0.2, 0.2, 0.0, 0.2, 0.2, 0.0]               0.142857   \n",
       "143                [0.2, 0.0, 0.0, 0.0, 0.4, 0.4, 0.0]               0.142857   \n",
       "\n",
       "     averaged_recall_test                                    precision_train  \\\n",
       "0                0.453465  [0.3923431594126644, 0.4582671777499705, 0.382...   \n",
       "1                0.281088  [0.2850857940170572, 0.2471789073476965, 0.233...   \n",
       "2                0.425392  [0.4713139798855225, 0.4143381572073497, 0.313...   \n",
       "3                0.467065  [0.40255447100242014, 0.397145191949951, 0.459...   \n",
       "4                0.268520  [0.22030669708290626, 0.2214708161247449, 0.13...   \n",
       "..                    ...                                                ...   \n",
       "139              0.142857  [0.028775510204081634, 0.0, 0.0, 0.0, 0.0, 0.1...   \n",
       "140              0.142857  [0.028775510204081634, 0.02811224489795918, 0....   \n",
       "141              0.142857  [0.0, 0.02857142857142857, 0.02806122448979591...   \n",
       "142              0.142857  [0.028775510204081634, 0.028520408163265305, 0...   \n",
       "143              0.142857  [0.028775510204081634, 0.0, 0.0, 0.0, 0.057602...   \n",
       "\n",
       "                                        precision_test  \\\n",
       "0    [0.35207534729986034, 0.3796717171717171, 0.35...   \n",
       "1    [0.4244749380598437, 0.24591828080953, 0.17545...   \n",
       "2    [0.35781766024912004, 0.3630360986918364, 0.29...   \n",
       "3    [0.3486435172522411, 0.38564581583879814, 0.41...   \n",
       "4    [0.10364346128822381, 0.22680118760984924, 0.1...   \n",
       "..                                                 ...   \n",
       "139  [0.027755102040816326, 0.0, 0.0, 0.0, 0.0, 0.1...   \n",
       "140  [0.027755102040816326, 0.03040816326530612, 0....   \n",
       "141  [0.0, 0.02857142857142857, 0.03061224489795918...   \n",
       "142  [0.027755102040816326, 0.028775510204081634, 0...   \n",
       "143  [0.027755102040816326, 0.0, 0.0, 0.0, 0.055306...   \n",
       "\n",
       "     averaged_precision_train  averaged_precision_test  f1_train_average  \\\n",
       "0                    0.508026                 0.459296          0.499906   \n",
       "1                    0.330505                 0.328967          0.308071   \n",
       "2                    0.492767                 0.439270          0.480853   \n",
       "3                    0.520917                 0.484875          0.510949   \n",
       "4                    0.297552                 0.239952          0.284093   \n",
       "..                        ...                      ...               ...   \n",
       "139                  0.020488                 0.020087          0.035837   \n",
       "140                  0.020466                 0.020175          0.035804   \n",
       "141                  0.020262                 0.020991          0.035491   \n",
       "142                  0.020875                 0.018542          0.036427   \n",
       "143                  0.020379                 0.020525          0.035670   \n",
       "\n",
       "     f1_test_average  \n",
       "0           0.456362  \n",
       "1           0.303149  \n",
       "2           0.432220  \n",
       "3           0.475803  \n",
       "4           0.253433  \n",
       "..               ...  \n",
       "139         0.035222  \n",
       "140         0.035357  \n",
       "141         0.036604  \n",
       "142         0.032824  \n",
       "143         0.035893  \n",
       "\n",
       "[144 rows x 13 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "metrics_dnn = []\n",
    "\n",
    "for i, row in data_dnn.iterrows():\n",
    "\n",
    "    accuracy_fold_train = []\n",
    "    accuracy_fold_test = []\n",
    "\n",
    "    recall_fold_train = []\n",
    "    recall_fold_test = []\n",
    "\n",
    "    precision_fold_train = []\n",
    "    precision_fold_test = []\n",
    "\n",
    "    for iteration in row[\"results\"]:\n",
    "        \n",
    "        loss = iteration[\"loss_values\"]\n",
    "        conf_mat_train = np.array(iteration[\"confusion_matrix_train\"])\n",
    "        conf_mat_test = np.array(iteration[\"confusion_matrix_val\"])\n",
    "        \n",
    "        # Compute accuracy (7 classes)\n",
    "        total_train = conf_mat_train.sum()\n",
    "        total_test = conf_mat_test.sum()\n",
    "\n",
    "        accuracy_train = conf_mat_train.diagonal().sum() / total_train if total_train > 0 else 0\n",
    "        accuracy_test = conf_mat_test.diagonal().sum() / total_test if total_test > 0 else 0\n",
    "\n",
    "        # Compute recall and precision (per class)\n",
    "        recall_train = np.array([\n",
    "            conf_mat_train[i, i] / conf_mat_train[i, :].sum() if conf_mat_train[i, :].sum() > 0 else 0\n",
    "            for i in range(7)\n",
    "        ])\n",
    "        recall_test = np.array([\n",
    "            conf_mat_test[i, i] / conf_mat_test[i, :].sum() if conf_mat_test[i, :].sum() > 0 else 0\n",
    "            for i in range(7)\n",
    "        ])\n",
    "\n",
    "        precision_train = np.array([\n",
    "            conf_mat_train[i, i] / conf_mat_train[:, i].sum() if conf_mat_train[:, i].sum() > 0 else 0\n",
    "            for i in range(7)\n",
    "        ])\n",
    "        precision_test = np.array([\n",
    "            conf_mat_test[i, i] / conf_mat_test[:, i].sum() if conf_mat_test[:, i].sum() > 0 else 0\n",
    "            for i in range(7)\n",
    "        ])\n",
    "\n",
    "        accuracy_fold_train.append(accuracy_train)\n",
    "        accuracy_fold_test.append(accuracy_test)\n",
    "\n",
    "        recall_fold_train.append(recall_train)\n",
    "        recall_fold_test.append(recall_test)\n",
    "\n",
    "        precision_fold_train.append(precision_train)\n",
    "        precision_fold_test.append(precision_test)\n",
    "\n",
    "    # Compute mean across folds\n",
    "    accuracy_train = np.mean(accuracy_fold_train)\n",
    "    accuracy_test = np.mean(accuracy_fold_test)\n",
    "\n",
    "    recall_train = np.mean(recall_fold_train, axis=0)\n",
    "    recall_test = np.mean(recall_fold_test, axis=0)\n",
    "\n",
    "    precision_train = np.mean(precision_fold_train, axis=0)\n",
    "    precision_test = np.mean(precision_fold_test, axis=0)\n",
    "\n",
    "    average_recall_train = np.mean(recall_train)\n",
    "    average_recall_test = np.mean(recall_test)\n",
    "\n",
    "    average_precision_train = np.mean(precision_train)\n",
    "    average_precision_test = np.mean(precision_test)\n",
    "\n",
    "    f1_train_average = 2 * (average_precision_train * average_recall_train) / (average_precision_train + average_recall_train)\n",
    "    f1_test_average = 2 * (average_precision_test * average_recall_test) / (average_precision_test + average_recall_test) \n",
    "\n",
    "    metrics_dnn.append({\n",
    "        \"iteration\": i,\n",
    "        \"accuracy_train\": accuracy_train,\n",
    "        \"accuracy_test\": accuracy_test,\n",
    "        \"recall_train\": recall_train.tolist(),  # Convert to list for DataFrame compatibility\n",
    "        \"recall_test\": recall_test.tolist(),\n",
    "        \"averaged_recall_train\": average_recall_train,\n",
    "        \"averaged_recall_test\": average_recall_test,\n",
    "        \"precision_train\": precision_train.tolist(),\n",
    "        \"precision_test\": precision_test.tolist(),\n",
    "        \"averaged_precision_train\": average_precision_train,\n",
    "        \"averaged_precision_test\": average_precision_test,\n",
    "        \"f1_train_average\": f1_train_average,\n",
    "        \"f1_test_average\": f1_test_average\n",
    "    })\n",
    "\n",
    "metrics_dnn = pd.DataFrame(metrics_dnn)\n",
    "metrics_dnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.49206776874351155), np.float64(0.5411958702807196))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the max value for f1-score\n",
    "\n",
    "max_f1_test = metrics_dnn[\"f1_test_average\"].max()\n",
    "max_f1_train = metrics_dnn[\"f1_train_average\"].max()\n",
    "max_f1_test, max_f1_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aca",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
