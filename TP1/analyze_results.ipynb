{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_epochs</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>n_layers</th>\n",
       "      <th>activation_function</th>\n",
       "      <th>loss_function</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>Cross Entropy</td>\n",
       "      <td>ADAM</td>\n",
       "      <td>[{'loss_values': [232.88340389728546, 219.4525...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>Cross Entropy</td>\n",
       "      <td>SGD</td>\n",
       "      <td>[{'loss_values': [239.34742295742035, 239.1654...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>Cross Entropy</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>[{'loss_values': [1311.3456435203552, 228.9097...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>Multi Margin</td>\n",
       "      <td>ADAM</td>\n",
       "      <td>[{'loss_values': [90.5774205327034, 81.7014083...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>Multi Margin</td>\n",
       "      <td>SGD</td>\n",
       "      <td>[{'loss_values': [105.32916295528412, 105.0802...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>50</td>\n",
       "      <td>64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>Cross Entropy</td>\n",
       "      <td>SGD</td>\n",
       "      <td>[{'loss_values': [164.53463542461395, 124.4378...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>50</td>\n",
       "      <td>64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>Cross Entropy</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>[{'loss_values': [12514.1414488554, 5595.03428...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>50</td>\n",
       "      <td>64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>Multi Margin</td>\n",
       "      <td>ADAM</td>\n",
       "      <td>[{'loss_values': [504.3324379324913, 226.14446...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>50</td>\n",
       "      <td>64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>Multi Margin</td>\n",
       "      <td>SGD</td>\n",
       "      <td>[{'loss_values': [67.28866493701935, 59.539265...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>50</td>\n",
       "      <td>64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>Multi Margin</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>[{'loss_values': [2768.8179498314857, 1365.907...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_epochs batch_size learning_rate n_layers activation_function  \\\n",
       "0         50         32         0.001        3                relu   \n",
       "1         50         32         0.001        3                relu   \n",
       "2         50         32         0.001        3                relu   \n",
       "3         50         32         0.001        3                relu   \n",
       "4         50         32         0.001        3                relu   \n",
       "..       ...        ...           ...      ...                 ...   \n",
       "139       50         64           0.1       15             sigmoid   \n",
       "140       50         64           0.1       15             sigmoid   \n",
       "141       50         64           0.1       15             sigmoid   \n",
       "142       50         64           0.1       15             sigmoid   \n",
       "143       50         64           0.1       15             sigmoid   \n",
       "\n",
       "     loss_function optimizer  \\\n",
       "0    Cross Entropy      ADAM   \n",
       "1    Cross Entropy       SGD   \n",
       "2    Cross Entropy   RMSprop   \n",
       "3     Multi Margin      ADAM   \n",
       "4     Multi Margin       SGD   \n",
       "..             ...       ...   \n",
       "139  Cross Entropy       SGD   \n",
       "140  Cross Entropy   RMSprop   \n",
       "141   Multi Margin      ADAM   \n",
       "142   Multi Margin       SGD   \n",
       "143   Multi Margin   RMSprop   \n",
       "\n",
       "                                               results  \n",
       "0    [{'loss_values': [232.88340389728546, 219.4525...  \n",
       "1    [{'loss_values': [239.34742295742035, 239.1654...  \n",
       "2    [{'loss_values': [1311.3456435203552, 228.9097...  \n",
       "3    [{'loss_values': [90.5774205327034, 81.7014083...  \n",
       "4    [{'loss_values': [105.32916295528412, 105.0802...  \n",
       "..                                                 ...  \n",
       "139  [{'loss_values': [164.53463542461395, 124.4378...  \n",
       "140  [{'loss_values': [12514.1414488554, 5595.03428...  \n",
       "141  [{'loss_values': [504.3324379324913, 226.14446...  \n",
       "142  [{'loss_values': [67.28866493701935, 59.539265...  \n",
       "143  [{'loss_values': [2768.8179498314857, 1365.907...  \n",
       "\n",
       "[144 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dnn = pd.read_json('results_dnn.json').T\n",
    "\n",
    "data_dnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>recall_train</th>\n",
       "      <th>recall_test</th>\n",
       "      <th>averaged_recall_train</th>\n",
       "      <th>averaged_recall_test</th>\n",
       "      <th>precision_train</th>\n",
       "      <th>precision_test</th>\n",
       "      <th>averaged_precision_train</th>\n",
       "      <th>averaged_precision_test</th>\n",
       "      <th>f1_train_average</th>\n",
       "      <th>f1_test_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.492194</td>\n",
       "      <td>0.452449</td>\n",
       "      <td>[0.45666576580645024, 0.2781380793631726, 0.41...</td>\n",
       "      <td>[0.39492310575368617, 0.26124302397151344, 0.3...</td>\n",
       "      <td>0.492041</td>\n",
       "      <td>0.453465</td>\n",
       "      <td>[0.3923431594126644, 0.4582671777499705, 0.382...</td>\n",
       "      <td>[0.35207534729986034, 0.3796717171717171, 0.35...</td>\n",
       "      <td>0.508026</td>\n",
       "      <td>0.459296</td>\n",
       "      <td>0.499906</td>\n",
       "      <td>0.456362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.289694</td>\n",
       "      <td>0.276531</td>\n",
       "      <td>[0.10461486097624861, 0.535960678336236, 0.091...</td>\n",
       "      <td>[0.0926535974196895, 0.540545522099994, 0.0831...</td>\n",
       "      <td>0.288489</td>\n",
       "      <td>0.281088</td>\n",
       "      <td>[0.2850857940170572, 0.2471789073476965, 0.233...</td>\n",
       "      <td>[0.4244749380598437, 0.24591828080953, 0.17545...</td>\n",
       "      <td>0.330505</td>\n",
       "      <td>0.328967</td>\n",
       "      <td>0.308071</td>\n",
       "      <td>0.303149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.469490</td>\n",
       "      <td>0.425714</td>\n",
       "      <td>[0.22926222423077203, 0.2317780149045233, 0.46...</td>\n",
       "      <td>[0.17854807761175776, 0.18497423247048367, 0.4...</td>\n",
       "      <td>0.469501</td>\n",
       "      <td>0.425392</td>\n",
       "      <td>[0.4713139798855225, 0.4143381572073497, 0.313...</td>\n",
       "      <td>[0.35781766024912004, 0.3630360986918364, 0.29...</td>\n",
       "      <td>0.492767</td>\n",
       "      <td>0.439270</td>\n",
       "      <td>0.480853</td>\n",
       "      <td>0.432220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.500663</td>\n",
       "      <td>0.470204</td>\n",
       "      <td>[0.42116714317564297, 0.3971881422840021, 0.37...</td>\n",
       "      <td>[0.3596384879068333, 0.3887226116726817, 0.346...</td>\n",
       "      <td>0.501354</td>\n",
       "      <td>0.467065</td>\n",
       "      <td>[0.40255447100242014, 0.397145191949951, 0.459...</td>\n",
       "      <td>[0.3486435172522411, 0.38564581583879814, 0.41...</td>\n",
       "      <td>0.520917</td>\n",
       "      <td>0.484875</td>\n",
       "      <td>0.510949</td>\n",
       "      <td>0.475803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.273878</td>\n",
       "      <td>0.260612</td>\n",
       "      <td>[0.12795219917516099, 0.6912996932283679, 0.17...</td>\n",
       "      <td>[0.12190061903965199, 0.6954819776464157, 0.16...</td>\n",
       "      <td>0.271799</td>\n",
       "      <td>0.268520</td>\n",
       "      <td>[0.22030669708290626, 0.2214708161247449, 0.13...</td>\n",
       "      <td>[0.10364346128822381, 0.22680118760984924, 0.1...</td>\n",
       "      <td>0.297552</td>\n",
       "      <td>0.239952</td>\n",
       "      <td>0.284093</td>\n",
       "      <td>0.253433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>139</td>\n",
       "      <td>0.143418</td>\n",
       "      <td>0.140612</td>\n",
       "      <td>[0.2, 0.0, 0.0, 0.0, 0.0, 0.8, 0.0]</td>\n",
       "      <td>[0.2, 0.0, 0.0, 0.0, 0.0, 0.8, 0.0]</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>[0.028775510204081634, 0.0, 0.0, 0.0, 0.0, 0.1...</td>\n",
       "      <td>[0.027755102040816326, 0.0, 0.0, 0.0, 0.0, 0.1...</td>\n",
       "      <td>0.020488</td>\n",
       "      <td>0.020087</td>\n",
       "      <td>0.035837</td>\n",
       "      <td>0.035222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>140</td>\n",
       "      <td>0.143265</td>\n",
       "      <td>0.141224</td>\n",
       "      <td>[0.2, 0.2, 0.0, 0.2, 0.0, 0.4, 0.0]</td>\n",
       "      <td>[0.2, 0.2, 0.0, 0.2, 0.0, 0.4, 0.0]</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>[0.028775510204081634, 0.02811224489795918, 0....</td>\n",
       "      <td>[0.027755102040816326, 0.03040816326530612, 0....</td>\n",
       "      <td>0.020466</td>\n",
       "      <td>0.020175</td>\n",
       "      <td>0.035804</td>\n",
       "      <td>0.035357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>141</td>\n",
       "      <td>0.141837</td>\n",
       "      <td>0.146939</td>\n",
       "      <td>[0.0, 0.2, 0.2, 0.0, 0.2, 0.2, 0.2]</td>\n",
       "      <td>[0.0, 0.2, 0.2, 0.0, 0.2, 0.2, 0.2]</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>[0.0, 0.02857142857142857, 0.02806122448979591...</td>\n",
       "      <td>[0.0, 0.02857142857142857, 0.03061224489795918...</td>\n",
       "      <td>0.020262</td>\n",
       "      <td>0.020991</td>\n",
       "      <td>0.035491</td>\n",
       "      <td>0.036604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>142</td>\n",
       "      <td>0.146122</td>\n",
       "      <td>0.129796</td>\n",
       "      <td>[0.2, 0.2, 0.2, 0.0, 0.2, 0.2, 0.0]</td>\n",
       "      <td>[0.2, 0.2, 0.2, 0.0, 0.2, 0.2, 0.0]</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>[0.028775510204081634, 0.028520408163265305, 0...</td>\n",
       "      <td>[0.027755102040816326, 0.028775510204081634, 0...</td>\n",
       "      <td>0.020875</td>\n",
       "      <td>0.018542</td>\n",
       "      <td>0.036427</td>\n",
       "      <td>0.032824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>143</td>\n",
       "      <td>0.142653</td>\n",
       "      <td>0.143673</td>\n",
       "      <td>[0.2, 0.0, 0.0, 0.0, 0.4, 0.4, 0.0]</td>\n",
       "      <td>[0.2, 0.0, 0.0, 0.0, 0.4, 0.4, 0.0]</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>[0.028775510204081634, 0.0, 0.0, 0.0, 0.057602...</td>\n",
       "      <td>[0.027755102040816326, 0.0, 0.0, 0.0, 0.055306...</td>\n",
       "      <td>0.020379</td>\n",
       "      <td>0.020525</td>\n",
       "      <td>0.035670</td>\n",
       "      <td>0.035893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     iteration  accuracy_train  accuracy_test  \\\n",
       "0            0        0.492194       0.452449   \n",
       "1            1        0.289694       0.276531   \n",
       "2            2        0.469490       0.425714   \n",
       "3            3        0.500663       0.470204   \n",
       "4            4        0.273878       0.260612   \n",
       "..         ...             ...            ...   \n",
       "139        139        0.143418       0.140612   \n",
       "140        140        0.143265       0.141224   \n",
       "141        141        0.141837       0.146939   \n",
       "142        142        0.146122       0.129796   \n",
       "143        143        0.142653       0.143673   \n",
       "\n",
       "                                          recall_train  \\\n",
       "0    [0.45666576580645024, 0.2781380793631726, 0.41...   \n",
       "1    [0.10461486097624861, 0.535960678336236, 0.091...   \n",
       "2    [0.22926222423077203, 0.2317780149045233, 0.46...   \n",
       "3    [0.42116714317564297, 0.3971881422840021, 0.37...   \n",
       "4    [0.12795219917516099, 0.6912996932283679, 0.17...   \n",
       "..                                                 ...   \n",
       "139                [0.2, 0.0, 0.0, 0.0, 0.0, 0.8, 0.0]   \n",
       "140                [0.2, 0.2, 0.0, 0.2, 0.0, 0.4, 0.0]   \n",
       "141                [0.0, 0.2, 0.2, 0.0, 0.2, 0.2, 0.2]   \n",
       "142                [0.2, 0.2, 0.2, 0.0, 0.2, 0.2, 0.0]   \n",
       "143                [0.2, 0.0, 0.0, 0.0, 0.4, 0.4, 0.0]   \n",
       "\n",
       "                                           recall_test  averaged_recall_train  \\\n",
       "0    [0.39492310575368617, 0.26124302397151344, 0.3...               0.492041   \n",
       "1    [0.0926535974196895, 0.540545522099994, 0.0831...               0.288489   \n",
       "2    [0.17854807761175776, 0.18497423247048367, 0.4...               0.469501   \n",
       "3    [0.3596384879068333, 0.3887226116726817, 0.346...               0.501354   \n",
       "4    [0.12190061903965199, 0.6954819776464157, 0.16...               0.271799   \n",
       "..                                                 ...                    ...   \n",
       "139                [0.2, 0.0, 0.0, 0.0, 0.0, 0.8, 0.0]               0.142857   \n",
       "140                [0.2, 0.2, 0.0, 0.2, 0.0, 0.4, 0.0]               0.142857   \n",
       "141                [0.0, 0.2, 0.2, 0.0, 0.2, 0.2, 0.2]               0.142857   \n",
       "142                [0.2, 0.2, 0.2, 0.0, 0.2, 0.2, 0.0]               0.142857   \n",
       "143                [0.2, 0.0, 0.0, 0.0, 0.4, 0.4, 0.0]               0.142857   \n",
       "\n",
       "     averaged_recall_test                                    precision_train  \\\n",
       "0                0.453465  [0.3923431594126644, 0.4582671777499705, 0.382...   \n",
       "1                0.281088  [0.2850857940170572, 0.2471789073476965, 0.233...   \n",
       "2                0.425392  [0.4713139798855225, 0.4143381572073497, 0.313...   \n",
       "3                0.467065  [0.40255447100242014, 0.397145191949951, 0.459...   \n",
       "4                0.268520  [0.22030669708290626, 0.2214708161247449, 0.13...   \n",
       "..                    ...                                                ...   \n",
       "139              0.142857  [0.028775510204081634, 0.0, 0.0, 0.0, 0.0, 0.1...   \n",
       "140              0.142857  [0.028775510204081634, 0.02811224489795918, 0....   \n",
       "141              0.142857  [0.0, 0.02857142857142857, 0.02806122448979591...   \n",
       "142              0.142857  [0.028775510204081634, 0.028520408163265305, 0...   \n",
       "143              0.142857  [0.028775510204081634, 0.0, 0.0, 0.0, 0.057602...   \n",
       "\n",
       "                                        precision_test  \\\n",
       "0    [0.35207534729986034, 0.3796717171717171, 0.35...   \n",
       "1    [0.4244749380598437, 0.24591828080953, 0.17545...   \n",
       "2    [0.35781766024912004, 0.3630360986918364, 0.29...   \n",
       "3    [0.3486435172522411, 0.38564581583879814, 0.41...   \n",
       "4    [0.10364346128822381, 0.22680118760984924, 0.1...   \n",
       "..                                                 ...   \n",
       "139  [0.027755102040816326, 0.0, 0.0, 0.0, 0.0, 0.1...   \n",
       "140  [0.027755102040816326, 0.03040816326530612, 0....   \n",
       "141  [0.0, 0.02857142857142857, 0.03061224489795918...   \n",
       "142  [0.027755102040816326, 0.028775510204081634, 0...   \n",
       "143  [0.027755102040816326, 0.0, 0.0, 0.0, 0.055306...   \n",
       "\n",
       "     averaged_precision_train  averaged_precision_test  f1_train_average  \\\n",
       "0                    0.508026                 0.459296          0.499906   \n",
       "1                    0.330505                 0.328967          0.308071   \n",
       "2                    0.492767                 0.439270          0.480853   \n",
       "3                    0.520917                 0.484875          0.510949   \n",
       "4                    0.297552                 0.239952          0.284093   \n",
       "..                        ...                      ...               ...   \n",
       "139                  0.020488                 0.020087          0.035837   \n",
       "140                  0.020466                 0.020175          0.035804   \n",
       "141                  0.020262                 0.020991          0.035491   \n",
       "142                  0.020875                 0.018542          0.036427   \n",
       "143                  0.020379                 0.020525          0.035670   \n",
       "\n",
       "     f1_test_average  \n",
       "0           0.456362  \n",
       "1           0.303149  \n",
       "2           0.432220  \n",
       "3           0.475803  \n",
       "4           0.253433  \n",
       "..               ...  \n",
       "139         0.035222  \n",
       "140         0.035357  \n",
       "141         0.036604  \n",
       "142         0.032824  \n",
       "143         0.035893  \n",
       "\n",
       "[144 rows x 13 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_dnn = []\n",
    "\n",
    "for i, row in data_dnn.iterrows():\n",
    "\n",
    "    accuracy_fold_train = []\n",
    "    accuracy_fold_test = []\n",
    "\n",
    "    recall_fold_train = []\n",
    "    recall_fold_test = []\n",
    "\n",
    "    precision_fold_train = []\n",
    "    precision_fold_test = []\n",
    "\n",
    "    for iteration in row[\"results\"]:\n",
    "        \n",
    "        loss = iteration[\"loss_values\"]\n",
    "        conf_mat_train = np.array(iteration[\"confusion_matrix_train\"])\n",
    "        conf_mat_test = np.array(iteration[\"confusion_matrix_val\"])\n",
    "        \n",
    "        # Compute accuracy (7 classes)\n",
    "        total_train = conf_mat_train.sum()\n",
    "        total_test = conf_mat_test.sum()\n",
    "\n",
    "        accuracy_train = conf_mat_train.diagonal().sum() / total_train if total_train > 0 else 0\n",
    "        accuracy_test = conf_mat_test.diagonal().sum() / total_test if total_test > 0 else 0\n",
    "\n",
    "        # Compute recall and precision (per class)\n",
    "        recall_train = np.array([\n",
    "            conf_mat_train[i, i] / conf_mat_train[i, :].sum() if conf_mat_train[i, :].sum() > 0 else 0\n",
    "            for i in range(7)\n",
    "        ])\n",
    "        recall_test = np.array([\n",
    "            conf_mat_test[i, i] / conf_mat_test[i, :].sum() if conf_mat_test[i, :].sum() > 0 else 0\n",
    "            for i in range(7)\n",
    "        ])\n",
    "\n",
    "        precision_train = np.array([\n",
    "            conf_mat_train[i, i] / conf_mat_train[:, i].sum() if conf_mat_train[:, i].sum() > 0 else 0\n",
    "            for i in range(7)\n",
    "        ])\n",
    "        precision_test = np.array([\n",
    "            conf_mat_test[i, i] / conf_mat_test[:, i].sum() if conf_mat_test[:, i].sum() > 0 else 0\n",
    "            for i in range(7)\n",
    "        ])\n",
    "\n",
    "        accuracy_fold_train.append(accuracy_train)\n",
    "        accuracy_fold_test.append(accuracy_test)\n",
    "\n",
    "        recall_fold_train.append(recall_train)\n",
    "        recall_fold_test.append(recall_test)\n",
    "\n",
    "        precision_fold_train.append(precision_train)\n",
    "        precision_fold_test.append(precision_test)\n",
    "\n",
    "    # Compute mean across folds\n",
    "    accuracy_train = np.mean(accuracy_fold_train)\n",
    "    accuracy_test = np.mean(accuracy_fold_test)\n",
    "\n",
    "    recall_train = np.mean(recall_fold_train, axis=0)\n",
    "    recall_test = np.mean(recall_fold_test, axis=0)\n",
    "\n",
    "    precision_train = np.mean(precision_fold_train, axis=0)\n",
    "    precision_test = np.mean(precision_fold_test, axis=0)\n",
    "\n",
    "    average_recall_train = np.mean(recall_train)\n",
    "    average_recall_test = np.mean(recall_test)\n",
    "\n",
    "    average_precision_train = np.mean(precision_train)\n",
    "    average_precision_test = np.mean(precision_test)\n",
    "\n",
    "    f1_train_average = 2 * (average_precision_train * average_recall_train) / (average_precision_train + average_recall_train)\n",
    "    f1_test_average = 2 * (average_precision_test * average_recall_test) / (average_precision_test + average_recall_test) \n",
    "\n",
    "    metrics_dnn.append({\n",
    "        \"iteration\": i,\n",
    "        \"accuracy_train\": accuracy_train,\n",
    "        \"accuracy_test\": accuracy_test,\n",
    "        \"recall_train\": recall_train.tolist(),  # Convert to list for DataFrame compatibility\n",
    "        \"recall_test\": recall_test.tolist(),\n",
    "        \"averaged_recall_train\": average_recall_train,\n",
    "        \"averaged_recall_test\": average_recall_test,\n",
    "        \"precision_train\": precision_train.tolist(),\n",
    "        \"precision_test\": precision_test.tolist(),\n",
    "        \"averaged_precision_train\": average_precision_train,\n",
    "        \"averaged_precision_test\": average_precision_test,\n",
    "        \"f1_train_average\": f1_train_average,\n",
    "        \"f1_test_average\": f1_test_average\n",
    "    })\n",
    "\n",
    "metrics_dnn = pd.DataFrame(metrics_dnn)\n",
    "metrics_dnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.49206776874351155), np.float64(0.5411958702807196))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the max value for f1-score\n",
    "\n",
    "max_f1_test = metrics_dnn[\"f1_test_average\"].max()\n",
    "max_f1_train = metrics_dnn[\"f1_train_average\"].max()\n",
    "max_f1_test, max_f1_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_epochs</th>\n",
       "      <th>activation_function</th>\n",
       "      <th>pooling</th>\n",
       "      <th>n_conv_layers</th>\n",
       "      <th>conv_out_channels</th>\n",
       "      <th>conv_kernel_size</th>\n",
       "      <th>conv_padding</th>\n",
       "      <th>n_layers</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>loss_function</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>MaxPool</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>Cross Entropy</td>\n",
       "      <td>ADAM</td>\n",
       "      <td>[{'loss_values': [231.8701878786087, 197.12700...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>MaxPool</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>Cross Entropy</td>\n",
       "      <td>SGD</td>\n",
       "      <td>[{'loss_values': [239.3160616159439, 239.26000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>MaxPool</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>Cross Entropy</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>[{'loss_values': [5110.887897610664, 220.26268...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>MaxPool</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>Multi Margin</td>\n",
       "      <td>ADAM</td>\n",
       "      <td>[{'loss_values': [86.5283233821392, 55.5496368...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>MaxPool</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>Multi Margin</td>\n",
       "      <td>SGD</td>\n",
       "      <td>[{'loss_values': [105.38043284416199, 105.3138...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>MaxPool</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>Multi Margin</td>\n",
       "      <td>ADAM</td>\n",
       "      <td>[{'loss_values': [105.79210501909256, 105.7310...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>MaxPool</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>Multi Margin</td>\n",
       "      <td>SGD</td>\n",
       "      <td>[{'loss_values': [105.42678338289261, 105.4261...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>MaxPool</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>Multi Margin</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>[{'loss_values': [133.8521836400032, 105.55857...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>MaxPool</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>Cross Entropy</td>\n",
       "      <td>ADAM</td>\n",
       "      <td>[{'loss_values': [652.23493039608, 239.5660724...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>MaxPool</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>Cross Entropy</td>\n",
       "      <td>SGD</td>\n",
       "      <td>[{'loss_values': [239.39001274108887, 239.3778...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_epochs activation_function  pooling n_conv_layers conv_out_channels  \\\n",
       "0         50                relu  MaxPool             1                16   \n",
       "1         50                relu  MaxPool             1                16   \n",
       "2         50                relu  MaxPool             1                16   \n",
       "3         50                relu  MaxPool             1                16   \n",
       "4         50                relu  MaxPool             1                16   \n",
       "..       ...                 ...      ...           ...               ...   \n",
       "111       50                relu  MaxPool             2                16   \n",
       "112       50                relu  MaxPool             2                16   \n",
       "113       50                relu  MaxPool             2                16   \n",
       "114       50                relu  MaxPool             2                16   \n",
       "115       50                relu  MaxPool             2                16   \n",
       "\n",
       "    conv_kernel_size conv_padding n_layers batch_size learning_rate  \\\n",
       "0                  3            1        3         32         0.001   \n",
       "1                  3            1        3         32         0.001   \n",
       "2                  3            1        3         32         0.001   \n",
       "3                  3            1        3         32         0.001   \n",
       "4                  3            1        3         32         0.001   \n",
       "..               ...          ...      ...        ...           ...   \n",
       "111                3            1       15         32         0.001   \n",
       "112                3            1       15         32         0.001   \n",
       "113                3            1       15         32         0.001   \n",
       "114                3            1       15         32          0.01   \n",
       "115                3            1       15         32          0.01   \n",
       "\n",
       "     loss_function optimizer  \\\n",
       "0    Cross Entropy      ADAM   \n",
       "1    Cross Entropy       SGD   \n",
       "2    Cross Entropy   RMSprop   \n",
       "3     Multi Margin      ADAM   \n",
       "4     Multi Margin       SGD   \n",
       "..             ...       ...   \n",
       "111   Multi Margin      ADAM   \n",
       "112   Multi Margin       SGD   \n",
       "113   Multi Margin   RMSprop   \n",
       "114  Cross Entropy      ADAM   \n",
       "115  Cross Entropy       SGD   \n",
       "\n",
       "                                               results  \n",
       "0    [{'loss_values': [231.8701878786087, 197.12700...  \n",
       "1    [{'loss_values': [239.3160616159439, 239.26000...  \n",
       "2    [{'loss_values': [5110.887897610664, 220.26268...  \n",
       "3    [{'loss_values': [86.5283233821392, 55.5496368...  \n",
       "4    [{'loss_values': [105.38043284416199, 105.3138...  \n",
       "..                                                 ...  \n",
       "111  [{'loss_values': [105.79210501909256, 105.7310...  \n",
       "112  [{'loss_values': [105.42678338289261, 105.4261...  \n",
       "113  [{'loss_values': [133.8521836400032, 105.55857...  \n",
       "114  [{'loss_values': [652.23493039608, 239.5660724...  \n",
       "115  [{'loss_values': [239.39001274108887, 239.3778...  \n",
       "\n",
       "[116 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cnn = pd.read_json('results_cnn_1.json').T\n",
    "\n",
    "data_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>recall_train</th>\n",
       "      <th>recall_test</th>\n",
       "      <th>averaged_recall_train</th>\n",
       "      <th>averaged_recall_test</th>\n",
       "      <th>precision_train</th>\n",
       "      <th>precision_test</th>\n",
       "      <th>averaged_precision_train</th>\n",
       "      <th>averaged_precision_test</th>\n",
       "      <th>f1_train_average</th>\n",
       "      <th>f1_test_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.878571</td>\n",
       "      <td>0.587959</td>\n",
       "      <td>[0.8783461695378652, 0.7727700035245286, 0.804...</td>\n",
       "      <td>[0.5332652149018743, 0.4189186747709572, 0.436...</td>\n",
       "      <td>0.878731</td>\n",
       "      <td>0.587685</td>\n",
       "      <td>[0.8394743897181787, 0.8892373590590665, 0.857...</td>\n",
       "      <td>[0.5007983883078934, 0.5383121861435812, 0.491...</td>\n",
       "      <td>0.882657</td>\n",
       "      <td>0.588455</td>\n",
       "      <td>0.880689</td>\n",
       "      <td>0.588070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.282704</td>\n",
       "      <td>0.272449</td>\n",
       "      <td>[0.18116847287235294, 0.6546719473864446, 0.00...</td>\n",
       "      <td>[0.17621491506095824, 0.6553112634440799, 0.00...</td>\n",
       "      <td>0.280925</td>\n",
       "      <td>0.279807</td>\n",
       "      <td>[0.23425496000797144, 0.23665133438647676, 0.1...</td>\n",
       "      <td>[0.18028448206330153, 0.23623675962678226, 0.0...</td>\n",
       "      <td>0.333323</td>\n",
       "      <td>0.311014</td>\n",
       "      <td>0.304889</td>\n",
       "      <td>0.294586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.907041</td>\n",
       "      <td>0.608980</td>\n",
       "      <td>[0.8266388045034054, 0.8962256848774655, 0.902...</td>\n",
       "      <td>[0.47887338277403957, 0.5030780299028847, 0.54...</td>\n",
       "      <td>0.907138</td>\n",
       "      <td>0.608596</td>\n",
       "      <td>[0.9468313178098764, 0.8848190094839643, 0.835...</td>\n",
       "      <td>[0.6046804023160028, 0.547976948165036, 0.4816...</td>\n",
       "      <td>0.914522</td>\n",
       "      <td>0.616030</td>\n",
       "      <td>0.910815</td>\n",
       "      <td>0.612291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.589388</td>\n",
       "      <td>[0.889013033613435, 0.8476563638588956, 0.8321...</td>\n",
       "      <td>[0.5350818736054895, 0.4777231375858392, 0.430...</td>\n",
       "      <td>0.900022</td>\n",
       "      <td>0.590088</td>\n",
       "      <td>[0.8566739641952855, 0.8641449562608097, 0.916...</td>\n",
       "      <td>[0.5015345071595071, 0.5263866979086214, 0.514...</td>\n",
       "      <td>0.903775</td>\n",
       "      <td>0.589573</td>\n",
       "      <td>0.901895</td>\n",
       "      <td>0.589830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.167449</td>\n",
       "      <td>0.152857</td>\n",
       "      <td>[0.12558665033680344, 0.5996485061511423, 0.0,...</td>\n",
       "      <td>[0.1215151515151515, 0.6, 0.0, 0.0, 0.00859595...</td>\n",
       "      <td>0.164875</td>\n",
       "      <td>0.162998</td>\n",
       "      <td>[0.05430857310628303, 0.09091184807202482, 0.0...</td>\n",
       "      <td>[0.046469622331691295, 0.08352534986527714, 0....</td>\n",
       "      <td>0.141456</td>\n",
       "      <td>0.105480</td>\n",
       "      <td>0.152270</td>\n",
       "      <td>0.128078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>111</td>\n",
       "      <td>0.145969</td>\n",
       "      <td>0.130408</td>\n",
       "      <td>[0.2, 0.2, 0.0, 0.2, 0.2, 0.0, 0.2]</td>\n",
       "      <td>[0.2, 0.2, 0.0, 0.2, 0.2, 0.0, 0.2]</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>[0.029336734693877552, 0.02923469387755102, 0....</td>\n",
       "      <td>[0.025510204081632654, 0.025918367346938774, 0...</td>\n",
       "      <td>0.020853</td>\n",
       "      <td>0.018630</td>\n",
       "      <td>0.036393</td>\n",
       "      <td>0.032961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>112</td>\n",
       "      <td>0.145510</td>\n",
       "      <td>0.132245</td>\n",
       "      <td>[0.2, 0.4, 0.4, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.2, 0.4, 0.4, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>[0.029336734693877552, 0.05790816326530612, 0....</td>\n",
       "      <td>[0.025510204081632654, 0.05408163265306123, 0....</td>\n",
       "      <td>0.020787</td>\n",
       "      <td>0.018892</td>\n",
       "      <td>0.036293</td>\n",
       "      <td>0.033371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>113</td>\n",
       "      <td>0.145969</td>\n",
       "      <td>0.130408</td>\n",
       "      <td>[0.2, 0.2, 0.0, 0.2, 0.2, 0.0, 0.2]</td>\n",
       "      <td>[0.2, 0.2, 0.0, 0.2, 0.2, 0.0, 0.2]</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>[0.029336734693877552, 0.02923469387755102, 0....</td>\n",
       "      <td>[0.025510204081632654, 0.025918367346938774, 0...</td>\n",
       "      <td>0.020853</td>\n",
       "      <td>0.018630</td>\n",
       "      <td>0.036393</td>\n",
       "      <td>0.032961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>114</td>\n",
       "      <td>0.145459</td>\n",
       "      <td>0.132449</td>\n",
       "      <td>[0.0, 0.2, 0.0, 0.4, 0.0, 0.0, 0.4]</td>\n",
       "      <td>[0.0, 0.2, 0.0, 0.4, 0.0, 0.0, 0.4]</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>[0.0, 0.02923469387755102, 0.0, 0.058163265306...</td>\n",
       "      <td>[0.0, 0.025918367346938774, 0.0, 0.05306122448...</td>\n",
       "      <td>0.020780</td>\n",
       "      <td>0.018921</td>\n",
       "      <td>0.036282</td>\n",
       "      <td>0.033417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>115</td>\n",
       "      <td>0.146786</td>\n",
       "      <td>0.127143</td>\n",
       "      <td>[0.2, 0.4, 0.2, 0.2, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.2, 0.4, 0.2, 0.2, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>[0.029336734693877552, 0.05826530612244898, 0....</td>\n",
       "      <td>[0.025510204081632654, 0.052653061224489796, 0...</td>\n",
       "      <td>0.020969</td>\n",
       "      <td>0.018163</td>\n",
       "      <td>0.036571</td>\n",
       "      <td>0.032229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     iteration  accuracy_train  accuracy_test  \\\n",
       "0            0        0.878571       0.587959   \n",
       "1            1        0.282704       0.272449   \n",
       "2            2        0.907041       0.608980   \n",
       "3            3        0.900000       0.589388   \n",
       "4            4        0.167449       0.152857   \n",
       "..         ...             ...            ...   \n",
       "111        111        0.145969       0.130408   \n",
       "112        112        0.145510       0.132245   \n",
       "113        113        0.145969       0.130408   \n",
       "114        114        0.145459       0.132449   \n",
       "115        115        0.146786       0.127143   \n",
       "\n",
       "                                          recall_train  \\\n",
       "0    [0.8783461695378652, 0.7727700035245286, 0.804...   \n",
       "1    [0.18116847287235294, 0.6546719473864446, 0.00...   \n",
       "2    [0.8266388045034054, 0.8962256848774655, 0.902...   \n",
       "3    [0.889013033613435, 0.8476563638588956, 0.8321...   \n",
       "4    [0.12558665033680344, 0.5996485061511423, 0.0,...   \n",
       "..                                                 ...   \n",
       "111                [0.2, 0.2, 0.0, 0.2, 0.2, 0.0, 0.2]   \n",
       "112                [0.2, 0.4, 0.4, 0.0, 0.0, 0.0, 0.0]   \n",
       "113                [0.2, 0.2, 0.0, 0.2, 0.2, 0.0, 0.2]   \n",
       "114                [0.0, 0.2, 0.0, 0.4, 0.0, 0.0, 0.4]   \n",
       "115                [0.2, 0.4, 0.2, 0.2, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                                           recall_test  averaged_recall_train  \\\n",
       "0    [0.5332652149018743, 0.4189186747709572, 0.436...               0.878731   \n",
       "1    [0.17621491506095824, 0.6553112634440799, 0.00...               0.280925   \n",
       "2    [0.47887338277403957, 0.5030780299028847, 0.54...               0.907138   \n",
       "3    [0.5350818736054895, 0.4777231375858392, 0.430...               0.900022   \n",
       "4    [0.1215151515151515, 0.6, 0.0, 0.0, 0.00859595...               0.164875   \n",
       "..                                                 ...                    ...   \n",
       "111                [0.2, 0.2, 0.0, 0.2, 0.2, 0.0, 0.2]               0.142857   \n",
       "112                [0.2, 0.4, 0.4, 0.0, 0.0, 0.0, 0.0]               0.142857   \n",
       "113                [0.2, 0.2, 0.0, 0.2, 0.2, 0.0, 0.2]               0.142857   \n",
       "114                [0.0, 0.2, 0.0, 0.4, 0.0, 0.0, 0.4]               0.142857   \n",
       "115                [0.2, 0.4, 0.2, 0.2, 0.0, 0.0, 0.0]               0.142857   \n",
       "\n",
       "     averaged_recall_test                                    precision_train  \\\n",
       "0                0.587685  [0.8394743897181787, 0.8892373590590665, 0.857...   \n",
       "1                0.279807  [0.23425496000797144, 0.23665133438647676, 0.1...   \n",
       "2                0.608596  [0.9468313178098764, 0.8848190094839643, 0.835...   \n",
       "3                0.590088  [0.8566739641952855, 0.8641449562608097, 0.916...   \n",
       "4                0.162998  [0.05430857310628303, 0.09091184807202482, 0.0...   \n",
       "..                    ...                                                ...   \n",
       "111              0.142857  [0.029336734693877552, 0.02923469387755102, 0....   \n",
       "112              0.142857  [0.029336734693877552, 0.05790816326530612, 0....   \n",
       "113              0.142857  [0.029336734693877552, 0.02923469387755102, 0....   \n",
       "114              0.142857  [0.0, 0.02923469387755102, 0.0, 0.058163265306...   \n",
       "115              0.142857  [0.029336734693877552, 0.05826530612244898, 0....   \n",
       "\n",
       "                                        precision_test  \\\n",
       "0    [0.5007983883078934, 0.5383121861435812, 0.491...   \n",
       "1    [0.18028448206330153, 0.23623675962678226, 0.0...   \n",
       "2    [0.6046804023160028, 0.547976948165036, 0.4816...   \n",
       "3    [0.5015345071595071, 0.5263866979086214, 0.514...   \n",
       "4    [0.046469622331691295, 0.08352534986527714, 0....   \n",
       "..                                                 ...   \n",
       "111  [0.025510204081632654, 0.025918367346938774, 0...   \n",
       "112  [0.025510204081632654, 0.05408163265306123, 0....   \n",
       "113  [0.025510204081632654, 0.025918367346938774, 0...   \n",
       "114  [0.0, 0.025918367346938774, 0.0, 0.05306122448...   \n",
       "115  [0.025510204081632654, 0.052653061224489796, 0...   \n",
       "\n",
       "     averaged_precision_train  averaged_precision_test  f1_train_average  \\\n",
       "0                    0.882657                 0.588455          0.880689   \n",
       "1                    0.333323                 0.311014          0.304889   \n",
       "2                    0.914522                 0.616030          0.910815   \n",
       "3                    0.903775                 0.589573          0.901895   \n",
       "4                    0.141456                 0.105480          0.152270   \n",
       "..                        ...                      ...               ...   \n",
       "111                  0.020853                 0.018630          0.036393   \n",
       "112                  0.020787                 0.018892          0.036293   \n",
       "113                  0.020853                 0.018630          0.036393   \n",
       "114                  0.020780                 0.018921          0.036282   \n",
       "115                  0.020969                 0.018163          0.036571   \n",
       "\n",
       "     f1_test_average  \n",
       "0           0.588070  \n",
       "1           0.294586  \n",
       "2           0.612291  \n",
       "3           0.589830  \n",
       "4           0.128078  \n",
       "..               ...  \n",
       "111         0.032961  \n",
       "112         0.033371  \n",
       "113         0.032961  \n",
       "114         0.033417  \n",
       "115         0.032229  \n",
       "\n",
       "[116 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_cnn = []\n",
    "\n",
    "for i, row in data_cnn.iterrows():\n",
    "\n",
    "    accuracy_fold_train = []\n",
    "    accuracy_fold_test = []\n",
    "\n",
    "    recall_fold_train = []\n",
    "    recall_fold_test = []\n",
    "\n",
    "    precision_fold_train = []\n",
    "    precision_fold_test = []\n",
    "\n",
    "    for iteration in row[\"results\"]:\n",
    "        \n",
    "        loss = iteration[\"loss_values\"]\n",
    "        conf_mat_train = np.array(iteration[\"confusion_matrix_train\"])\n",
    "        conf_mat_test = np.array(iteration[\"confusion_matrix_val\"])\n",
    "        \n",
    "        # Compute accuracy (7 classes)\n",
    "        total_train = conf_mat_train.sum()\n",
    "        total_test = conf_mat_test.sum()\n",
    "\n",
    "        accuracy_train = conf_mat_train.diagonal().sum() / total_train if total_train > 0 else 0\n",
    "        accuracy_test = conf_mat_test.diagonal().sum() / total_test if total_test > 0 else 0\n",
    "\n",
    "        # Compute recall and precision (per class)\n",
    "        recall_train = np.array([\n",
    "            conf_mat_train[i, i] / conf_mat_train[i, :].sum() if conf_mat_train[i, :].sum() > 0 else 0\n",
    "            for i in range(7)\n",
    "        ])\n",
    "        recall_test = np.array([\n",
    "            conf_mat_test[i, i] / conf_mat_test[i, :].sum() if conf_mat_test[i, :].sum() > 0 else 0\n",
    "            for i in range(7)\n",
    "        ])\n",
    "\n",
    "        precision_train = np.array([\n",
    "            conf_mat_train[i, i] / conf_mat_train[:, i].sum() if conf_mat_train[:, i].sum() > 0 else 0\n",
    "            for i in range(7)\n",
    "        ])\n",
    "        precision_test = np.array([\n",
    "            conf_mat_test[i, i] / conf_mat_test[:, i].sum() if conf_mat_test[:, i].sum() > 0 else 0\n",
    "            for i in range(7)\n",
    "        ])\n",
    "\n",
    "        accuracy_fold_train.append(accuracy_train)\n",
    "        accuracy_fold_test.append(accuracy_test)\n",
    "\n",
    "        recall_fold_train.append(recall_train)\n",
    "        recall_fold_test.append(recall_test)\n",
    "\n",
    "        precision_fold_train.append(precision_train)\n",
    "        precision_fold_test.append(precision_test)\n",
    "\n",
    "    # Compute mean across folds\n",
    "    accuracy_train = np.mean(accuracy_fold_train)\n",
    "    accuracy_test = np.mean(accuracy_fold_test)\n",
    "\n",
    "    recall_train = np.mean(recall_fold_train, axis=0)\n",
    "    recall_test = np.mean(recall_fold_test, axis=0)\n",
    "\n",
    "    precision_train = np.mean(precision_fold_train, axis=0)\n",
    "    precision_test = np.mean(precision_fold_test, axis=0)\n",
    "\n",
    "    average_recall_train = np.mean(recall_train)\n",
    "    average_recall_test = np.mean(recall_test)\n",
    "\n",
    "    average_precision_train = np.mean(precision_train)\n",
    "    average_precision_test = np.mean(precision_test)\n",
    "\n",
    "    f1_train_average = 2 * (average_precision_train * average_recall_train) / (average_precision_train + average_recall_train)\n",
    "    f1_test_average = 2 * (average_precision_test * average_recall_test) / (average_precision_test + average_recall_test) \n",
    "\n",
    "    metrics_cnn.append({\n",
    "        \"iteration\": i,\n",
    "        \"accuracy_train\": accuracy_train,\n",
    "        \"accuracy_test\": accuracy_test,\n",
    "        \"recall_train\": recall_train.tolist(),  # Convert to list for DataFrame compatibility\n",
    "        \"recall_test\": recall_test.tolist(),\n",
    "        \"averaged_recall_train\": average_recall_train,\n",
    "        \"averaged_recall_test\": average_recall_test,\n",
    "        \"precision_train\": precision_train.tolist(),\n",
    "        \"precision_test\": precision_test.tolist(),\n",
    "        \"averaged_precision_train\": average_precision_train,\n",
    "        \"averaged_precision_test\": average_precision_test,\n",
    "        \"f1_train_average\": f1_train_average,\n",
    "        \"f1_test_average\": f1_test_average\n",
    "    })\n",
    "\n",
    "metrics_cnn = pd.DataFrame(metrics_cnn)\n",
    "metrics_cnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.6551872819161952), np.float64(0.973445018550672))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_f1_train = metrics_cnn[\"f1_train_average\"].max()\n",
    "max_f1_test = metrics_cnn[\"f1_test_average\"].max()\n",
    "\n",
    "max_f1_test, max_f1_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aca",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
