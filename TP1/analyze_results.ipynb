{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_epochs</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>n_layers</th>\n",
       "      <th>activation_function</th>\n",
       "      <th>loss_function</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>Cross Entropy</td>\n",
       "      <td>ADAM</td>\n",
       "      <td>[{'loss_values': [232.88340389728546, 219.4525...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>Cross Entropy</td>\n",
       "      <td>SGD</td>\n",
       "      <td>[{'loss_values': [239.34742295742035, 239.1654...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>Cross Entropy</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>[{'loss_values': [1311.3456435203552, 228.9097...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>Multi Margin</td>\n",
       "      <td>ADAM</td>\n",
       "      <td>[{'loss_values': [90.5774205327034, 81.7014083...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>Multi Margin</td>\n",
       "      <td>SGD</td>\n",
       "      <td>[{'loss_values': [105.32916295528412, 105.0802...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>50</td>\n",
       "      <td>64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>Cross Entropy</td>\n",
       "      <td>SGD</td>\n",
       "      <td>[{'loss_values': [164.53463542461395, 124.4378...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>50</td>\n",
       "      <td>64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>Cross Entropy</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>[{'loss_values': [12514.1414488554, 5595.03428...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>50</td>\n",
       "      <td>64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>Multi Margin</td>\n",
       "      <td>ADAM</td>\n",
       "      <td>[{'loss_values': [504.3324379324913, 226.14446...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>50</td>\n",
       "      <td>64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>Multi Margin</td>\n",
       "      <td>SGD</td>\n",
       "      <td>[{'loss_values': [67.28866493701935, 59.539265...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>50</td>\n",
       "      <td>64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>Multi Margin</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>[{'loss_values': [2768.8179498314857, 1365.907...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_epochs batch_size learning_rate n_layers activation_function  \\\n",
       "0         50         32         0.001        3                relu   \n",
       "1         50         32         0.001        3                relu   \n",
       "2         50         32         0.001        3                relu   \n",
       "3         50         32         0.001        3                relu   \n",
       "4         50         32         0.001        3                relu   \n",
       "..       ...        ...           ...      ...                 ...   \n",
       "139       50         64           0.1       15             sigmoid   \n",
       "140       50         64           0.1       15             sigmoid   \n",
       "141       50         64           0.1       15             sigmoid   \n",
       "142       50         64           0.1       15             sigmoid   \n",
       "143       50         64           0.1       15             sigmoid   \n",
       "\n",
       "     loss_function optimizer  \\\n",
       "0    Cross Entropy      ADAM   \n",
       "1    Cross Entropy       SGD   \n",
       "2    Cross Entropy   RMSprop   \n",
       "3     Multi Margin      ADAM   \n",
       "4     Multi Margin       SGD   \n",
       "..             ...       ...   \n",
       "139  Cross Entropy       SGD   \n",
       "140  Cross Entropy   RMSprop   \n",
       "141   Multi Margin      ADAM   \n",
       "142   Multi Margin       SGD   \n",
       "143   Multi Margin   RMSprop   \n",
       "\n",
       "                                               results  \n",
       "0    [{'loss_values': [232.88340389728546, 219.4525...  \n",
       "1    [{'loss_values': [239.34742295742035, 239.1654...  \n",
       "2    [{'loss_values': [1311.3456435203552, 228.9097...  \n",
       "3    [{'loss_values': [90.5774205327034, 81.7014083...  \n",
       "4    [{'loss_values': [105.32916295528412, 105.0802...  \n",
       "..                                                 ...  \n",
       "139  [{'loss_values': [164.53463542461395, 124.4378...  \n",
       "140  [{'loss_values': [12514.1414488554, 5595.03428...  \n",
       "141  [{'loss_values': [504.3324379324913, 226.14446...  \n",
       "142  [{'loss_values': [67.28866493701935, 59.539265...  \n",
       "143  [{'loss_values': [2768.8179498314857, 1365.907...  \n",
       "\n",
       "[144 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dnn = pd.read_json('results_dnn.json').T\n",
    "\n",
    "data_dnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>recall_train</th>\n",
       "      <th>recall_test</th>\n",
       "      <th>averaged_recall_train</th>\n",
       "      <th>averaged_recall_test</th>\n",
       "      <th>precision_train</th>\n",
       "      <th>precision_test</th>\n",
       "      <th>averaged_precision_train</th>\n",
       "      <th>averaged_precision_test</th>\n",
       "      <th>f1_train_average</th>\n",
       "      <th>f1_test_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.492194</td>\n",
       "      <td>0.452449</td>\n",
       "      <td>[0.45666576580645024, 0.2781380793631726, 0.41...</td>\n",
       "      <td>[0.39492310575368617, 0.26124302397151344, 0.3...</td>\n",
       "      <td>0.492041</td>\n",
       "      <td>0.453465</td>\n",
       "      <td>[0.3923431594126644, 0.4582671777499705, 0.382...</td>\n",
       "      <td>[0.35207534729986034, 0.3796717171717171, 0.35...</td>\n",
       "      <td>0.508026</td>\n",
       "      <td>0.459296</td>\n",
       "      <td>0.499906</td>\n",
       "      <td>0.456362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.289694</td>\n",
       "      <td>0.276531</td>\n",
       "      <td>[0.10461486097624861, 0.535960678336236, 0.091...</td>\n",
       "      <td>[0.0926535974196895, 0.540545522099994, 0.0831...</td>\n",
       "      <td>0.288489</td>\n",
       "      <td>0.281088</td>\n",
       "      <td>[0.2850857940170572, 0.2471789073476965, 0.233...</td>\n",
       "      <td>[0.4244749380598437, 0.24591828080953, 0.17545...</td>\n",
       "      <td>0.330505</td>\n",
       "      <td>0.328967</td>\n",
       "      <td>0.308071</td>\n",
       "      <td>0.303149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.469490</td>\n",
       "      <td>0.425714</td>\n",
       "      <td>[0.22926222423077203, 0.2317780149045233, 0.46...</td>\n",
       "      <td>[0.17854807761175776, 0.18497423247048367, 0.4...</td>\n",
       "      <td>0.469501</td>\n",
       "      <td>0.425392</td>\n",
       "      <td>[0.4713139798855225, 0.4143381572073497, 0.313...</td>\n",
       "      <td>[0.35781766024912004, 0.3630360986918364, 0.29...</td>\n",
       "      <td>0.492767</td>\n",
       "      <td>0.439270</td>\n",
       "      <td>0.480853</td>\n",
       "      <td>0.432220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.500663</td>\n",
       "      <td>0.470204</td>\n",
       "      <td>[0.42116714317564297, 0.3971881422840021, 0.37...</td>\n",
       "      <td>[0.3596384879068333, 0.3887226116726817, 0.346...</td>\n",
       "      <td>0.501354</td>\n",
       "      <td>0.467065</td>\n",
       "      <td>[0.40255447100242014, 0.397145191949951, 0.459...</td>\n",
       "      <td>[0.3486435172522411, 0.38564581583879814, 0.41...</td>\n",
       "      <td>0.520917</td>\n",
       "      <td>0.484875</td>\n",
       "      <td>0.510949</td>\n",
       "      <td>0.475803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.273878</td>\n",
       "      <td>0.260612</td>\n",
       "      <td>[0.12795219917516099, 0.6912996932283679, 0.17...</td>\n",
       "      <td>[0.12190061903965199, 0.6954819776464157, 0.16...</td>\n",
       "      <td>0.271799</td>\n",
       "      <td>0.268520</td>\n",
       "      <td>[0.22030669708290626, 0.2214708161247449, 0.13...</td>\n",
       "      <td>[0.10364346128822381, 0.22680118760984924, 0.1...</td>\n",
       "      <td>0.297552</td>\n",
       "      <td>0.239952</td>\n",
       "      <td>0.284093</td>\n",
       "      <td>0.253433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>139</td>\n",
       "      <td>0.143418</td>\n",
       "      <td>0.140612</td>\n",
       "      <td>[0.2, 0.0, 0.0, 0.0, 0.0, 0.8, 0.0]</td>\n",
       "      <td>[0.2, 0.0, 0.0, 0.0, 0.0, 0.8, 0.0]</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>[0.028775510204081634, 0.0, 0.0, 0.0, 0.0, 0.1...</td>\n",
       "      <td>[0.027755102040816326, 0.0, 0.0, 0.0, 0.0, 0.1...</td>\n",
       "      <td>0.020488</td>\n",
       "      <td>0.020087</td>\n",
       "      <td>0.035837</td>\n",
       "      <td>0.035222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>140</td>\n",
       "      <td>0.143265</td>\n",
       "      <td>0.141224</td>\n",
       "      <td>[0.2, 0.2, 0.0, 0.2, 0.0, 0.4, 0.0]</td>\n",
       "      <td>[0.2, 0.2, 0.0, 0.2, 0.0, 0.4, 0.0]</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>[0.028775510204081634, 0.02811224489795918, 0....</td>\n",
       "      <td>[0.027755102040816326, 0.03040816326530612, 0....</td>\n",
       "      <td>0.020466</td>\n",
       "      <td>0.020175</td>\n",
       "      <td>0.035804</td>\n",
       "      <td>0.035357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>141</td>\n",
       "      <td>0.141837</td>\n",
       "      <td>0.146939</td>\n",
       "      <td>[0.0, 0.2, 0.2, 0.0, 0.2, 0.2, 0.2]</td>\n",
       "      <td>[0.0, 0.2, 0.2, 0.0, 0.2, 0.2, 0.2]</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>[0.0, 0.02857142857142857, 0.02806122448979591...</td>\n",
       "      <td>[0.0, 0.02857142857142857, 0.03061224489795918...</td>\n",
       "      <td>0.020262</td>\n",
       "      <td>0.020991</td>\n",
       "      <td>0.035491</td>\n",
       "      <td>0.036604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>142</td>\n",
       "      <td>0.146122</td>\n",
       "      <td>0.129796</td>\n",
       "      <td>[0.2, 0.2, 0.2, 0.0, 0.2, 0.2, 0.0]</td>\n",
       "      <td>[0.2, 0.2, 0.2, 0.0, 0.2, 0.2, 0.0]</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>[0.028775510204081634, 0.028520408163265305, 0...</td>\n",
       "      <td>[0.027755102040816326, 0.028775510204081634, 0...</td>\n",
       "      <td>0.020875</td>\n",
       "      <td>0.018542</td>\n",
       "      <td>0.036427</td>\n",
       "      <td>0.032824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>143</td>\n",
       "      <td>0.142653</td>\n",
       "      <td>0.143673</td>\n",
       "      <td>[0.2, 0.0, 0.0, 0.0, 0.4, 0.4, 0.0]</td>\n",
       "      <td>[0.2, 0.0, 0.0, 0.0, 0.4, 0.4, 0.0]</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>[0.028775510204081634, 0.0, 0.0, 0.0, 0.057602...</td>\n",
       "      <td>[0.027755102040816326, 0.0, 0.0, 0.0, 0.055306...</td>\n",
       "      <td>0.020379</td>\n",
       "      <td>0.020525</td>\n",
       "      <td>0.035670</td>\n",
       "      <td>0.035893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     iteration  accuracy_train  accuracy_test  \\\n",
       "0            0        0.492194       0.452449   \n",
       "1            1        0.289694       0.276531   \n",
       "2            2        0.469490       0.425714   \n",
       "3            3        0.500663       0.470204   \n",
       "4            4        0.273878       0.260612   \n",
       "..         ...             ...            ...   \n",
       "139        139        0.143418       0.140612   \n",
       "140        140        0.143265       0.141224   \n",
       "141        141        0.141837       0.146939   \n",
       "142        142        0.146122       0.129796   \n",
       "143        143        0.142653       0.143673   \n",
       "\n",
       "                                          recall_train  \\\n",
       "0    [0.45666576580645024, 0.2781380793631726, 0.41...   \n",
       "1    [0.10461486097624861, 0.535960678336236, 0.091...   \n",
       "2    [0.22926222423077203, 0.2317780149045233, 0.46...   \n",
       "3    [0.42116714317564297, 0.3971881422840021, 0.37...   \n",
       "4    [0.12795219917516099, 0.6912996932283679, 0.17...   \n",
       "..                                                 ...   \n",
       "139                [0.2, 0.0, 0.0, 0.0, 0.0, 0.8, 0.0]   \n",
       "140                [0.2, 0.2, 0.0, 0.2, 0.0, 0.4, 0.0]   \n",
       "141                [0.0, 0.2, 0.2, 0.0, 0.2, 0.2, 0.2]   \n",
       "142                [0.2, 0.2, 0.2, 0.0, 0.2, 0.2, 0.0]   \n",
       "143                [0.2, 0.0, 0.0, 0.0, 0.4, 0.4, 0.0]   \n",
       "\n",
       "                                           recall_test  averaged_recall_train  \\\n",
       "0    [0.39492310575368617, 0.26124302397151344, 0.3...               0.492041   \n",
       "1    [0.0926535974196895, 0.540545522099994, 0.0831...               0.288489   \n",
       "2    [0.17854807761175776, 0.18497423247048367, 0.4...               0.469501   \n",
       "3    [0.3596384879068333, 0.3887226116726817, 0.346...               0.501354   \n",
       "4    [0.12190061903965199, 0.6954819776464157, 0.16...               0.271799   \n",
       "..                                                 ...                    ...   \n",
       "139                [0.2, 0.0, 0.0, 0.0, 0.0, 0.8, 0.0]               0.142857   \n",
       "140                [0.2, 0.2, 0.0, 0.2, 0.0, 0.4, 0.0]               0.142857   \n",
       "141                [0.0, 0.2, 0.2, 0.0, 0.2, 0.2, 0.2]               0.142857   \n",
       "142                [0.2, 0.2, 0.2, 0.0, 0.2, 0.2, 0.0]               0.142857   \n",
       "143                [0.2, 0.0, 0.0, 0.0, 0.4, 0.4, 0.0]               0.142857   \n",
       "\n",
       "     averaged_recall_test                                    precision_train  \\\n",
       "0                0.453465  [0.3923431594126644, 0.4582671777499705, 0.382...   \n",
       "1                0.281088  [0.2850857940170572, 0.2471789073476965, 0.233...   \n",
       "2                0.425392  [0.4713139798855225, 0.4143381572073497, 0.313...   \n",
       "3                0.467065  [0.40255447100242014, 0.397145191949951, 0.459...   \n",
       "4                0.268520  [0.22030669708290626, 0.2214708161247449, 0.13...   \n",
       "..                    ...                                                ...   \n",
       "139              0.142857  [0.028775510204081634, 0.0, 0.0, 0.0, 0.0, 0.1...   \n",
       "140              0.142857  [0.028775510204081634, 0.02811224489795918, 0....   \n",
       "141              0.142857  [0.0, 0.02857142857142857, 0.02806122448979591...   \n",
       "142              0.142857  [0.028775510204081634, 0.028520408163265305, 0...   \n",
       "143              0.142857  [0.028775510204081634, 0.0, 0.0, 0.0, 0.057602...   \n",
       "\n",
       "                                        precision_test  \\\n",
       "0    [0.35207534729986034, 0.3796717171717171, 0.35...   \n",
       "1    [0.4244749380598437, 0.24591828080953, 0.17545...   \n",
       "2    [0.35781766024912004, 0.3630360986918364, 0.29...   \n",
       "3    [0.3486435172522411, 0.38564581583879814, 0.41...   \n",
       "4    [0.10364346128822381, 0.22680118760984924, 0.1...   \n",
       "..                                                 ...   \n",
       "139  [0.027755102040816326, 0.0, 0.0, 0.0, 0.0, 0.1...   \n",
       "140  [0.027755102040816326, 0.03040816326530612, 0....   \n",
       "141  [0.0, 0.02857142857142857, 0.03061224489795918...   \n",
       "142  [0.027755102040816326, 0.028775510204081634, 0...   \n",
       "143  [0.027755102040816326, 0.0, 0.0, 0.0, 0.055306...   \n",
       "\n",
       "     averaged_precision_train  averaged_precision_test  f1_train_average  \\\n",
       "0                    0.508026                 0.459296          0.499906   \n",
       "1                    0.330505                 0.328967          0.308071   \n",
       "2                    0.492767                 0.439270          0.480853   \n",
       "3                    0.520917                 0.484875          0.510949   \n",
       "4                    0.297552                 0.239952          0.284093   \n",
       "..                        ...                      ...               ...   \n",
       "139                  0.020488                 0.020087          0.035837   \n",
       "140                  0.020466                 0.020175          0.035804   \n",
       "141                  0.020262                 0.020991          0.035491   \n",
       "142                  0.020875                 0.018542          0.036427   \n",
       "143                  0.020379                 0.020525          0.035670   \n",
       "\n",
       "     f1_test_average  \n",
       "0           0.456362  \n",
       "1           0.303149  \n",
       "2           0.432220  \n",
       "3           0.475803  \n",
       "4           0.253433  \n",
       "..               ...  \n",
       "139         0.035222  \n",
       "140         0.035357  \n",
       "141         0.036604  \n",
       "142         0.032824  \n",
       "143         0.035893  \n",
       "\n",
       "[144 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_dnn = []\n",
    "\n",
    "for i, row in data_dnn.iterrows():\n",
    "\n",
    "    accuracy_fold_train = []\n",
    "    accuracy_fold_test = []\n",
    "\n",
    "    recall_fold_train = []\n",
    "    recall_fold_test = []\n",
    "\n",
    "    precision_fold_train = []\n",
    "    precision_fold_test = []\n",
    "\n",
    "    for iteration in row[\"results\"]:\n",
    "        \n",
    "        loss = iteration[\"loss_values\"]\n",
    "        conf_mat_train = np.array(iteration[\"confusion_matrix_train\"])\n",
    "        conf_mat_test = np.array(iteration[\"confusion_matrix_val\"])\n",
    "        \n",
    "        # Compute accuracy (7 classes)\n",
    "        total_train = conf_mat_train.sum()\n",
    "        total_test = conf_mat_test.sum()\n",
    "\n",
    "        accuracy_train = conf_mat_train.diagonal().sum() / total_train if total_train > 0 else 0\n",
    "        accuracy_test = conf_mat_test.diagonal().sum() / total_test if total_test > 0 else 0\n",
    "\n",
    "        # Compute recall and precision (per class)\n",
    "        recall_train = np.array([\n",
    "            conf_mat_train[i, i] / conf_mat_train[i, :].sum() if conf_mat_train[i, :].sum() > 0 else 0\n",
    "            for i in range(7)\n",
    "        ])\n",
    "        recall_test = np.array([\n",
    "            conf_mat_test[i, i] / conf_mat_test[i, :].sum() if conf_mat_test[i, :].sum() > 0 else 0\n",
    "            for i in range(7)\n",
    "        ])\n",
    "\n",
    "        precision_train = np.array([\n",
    "            conf_mat_train[i, i] / conf_mat_train[:, i].sum() if conf_mat_train[:, i].sum() > 0 else 0\n",
    "            for i in range(7)\n",
    "        ])\n",
    "        precision_test = np.array([\n",
    "            conf_mat_test[i, i] / conf_mat_test[:, i].sum() if conf_mat_test[:, i].sum() > 0 else 0\n",
    "            for i in range(7)\n",
    "        ])\n",
    "\n",
    "        accuracy_fold_train.append(accuracy_train)\n",
    "        accuracy_fold_test.append(accuracy_test)\n",
    "\n",
    "        recall_fold_train.append(recall_train)\n",
    "        recall_fold_test.append(recall_test)\n",
    "\n",
    "        precision_fold_train.append(precision_train)\n",
    "        precision_fold_test.append(precision_test)\n",
    "\n",
    "    # Compute mean across folds\n",
    "    accuracy_train = np.mean(accuracy_fold_train)\n",
    "    accuracy_test = np.mean(accuracy_fold_test)\n",
    "\n",
    "    recall_train = np.mean(recall_fold_train, axis=0)\n",
    "    recall_test = np.mean(recall_fold_test, axis=0)\n",
    "\n",
    "    precision_train = np.mean(precision_fold_train, axis=0)\n",
    "    precision_test = np.mean(precision_fold_test, axis=0)\n",
    "\n",
    "    average_recall_train = np.mean(recall_train)\n",
    "    average_recall_test = np.mean(recall_test)\n",
    "\n",
    "    average_precision_train = np.mean(precision_train)\n",
    "    average_precision_test = np.mean(precision_test)\n",
    "\n",
    "    f1_train_average = 2 * (average_precision_train * average_recall_train) / (average_precision_train + average_recall_train)\n",
    "    f1_test_average = 2 * (average_precision_test * average_recall_test) / (average_precision_test + average_recall_test) \n",
    "\n",
    "    metrics_dnn.append({\n",
    "        \"iteration\": i,\n",
    "        \"accuracy_train\": accuracy_train,\n",
    "        \"accuracy_test\": accuracy_test,\n",
    "        \"recall_train\": recall_train.tolist(),  # Convert to list for DataFrame compatibility\n",
    "        \"recall_test\": recall_test.tolist(),\n",
    "        \"averaged_recall_train\": average_recall_train,\n",
    "        \"averaged_recall_test\": average_recall_test,\n",
    "        \"precision_train\": precision_train.tolist(),\n",
    "        \"precision_test\": precision_test.tolist(),\n",
    "        \"averaged_precision_train\": average_precision_train,\n",
    "        \"averaged_precision_test\": average_precision_test,\n",
    "        \"f1_train_average\": f1_train_average,\n",
    "        \"f1_test_average\": f1_test_average\n",
    "    })\n",
    "\n",
    "metrics_dnn = pd.DataFrame(metrics_dnn)\n",
    "metrics_dnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.49206776874351155), np.float64(0.5411958702807196))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the max value for f1-score\n",
    "\n",
    "max_f1_test = metrics_dnn[\"f1_test_average\"].max()\n",
    "max_f1_train = metrics_dnn[\"f1_train_average\"].max()\n",
    "max_f1_test, max_f1_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_epochs</th>\n",
       "      <th>activation_function</th>\n",
       "      <th>pooling</th>\n",
       "      <th>n_conv_layers</th>\n",
       "      <th>conv_out_channels</th>\n",
       "      <th>conv_kernel_size</th>\n",
       "      <th>conv_padding</th>\n",
       "      <th>n_layers</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>loss_function</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>MaxPool</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>Cross Entropy</td>\n",
       "      <td>ADAM</td>\n",
       "      <td>[{'loss_values': [231.8701878786087, 197.12700...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>MaxPool</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>Cross Entropy</td>\n",
       "      <td>SGD</td>\n",
       "      <td>[{'loss_values': [239.3160616159439, 239.26000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>MaxPool</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>Cross Entropy</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>[{'loss_values': [5110.887897610664, 220.26268...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>MaxPool</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>Multi Margin</td>\n",
       "      <td>ADAM</td>\n",
       "      <td>[{'loss_values': [86.5283233821392, 55.5496368...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>MaxPool</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>Multi Margin</td>\n",
       "      <td>SGD</td>\n",
       "      <td>[{'loss_values': [105.38043284416199, 105.3138...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>50</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>AvgPool</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Cross Entropy</td>\n",
       "      <td>SGD</td>\n",
       "      <td>[{'loss_values': [283.7384283542633, 244.37010...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>50</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>AvgPool</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Cross Entropy</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>[{'loss_values': [12106.481934070587, 6383.127...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>50</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>AvgPool</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Multi Margin</td>\n",
       "      <td>ADAM</td>\n",
       "      <td>[{'loss_values': [630.6281946897507, 447.19764...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>50</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>AvgPool</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Multi Margin</td>\n",
       "      <td>SGD</td>\n",
       "      <td>[{'loss_values': [123.1793560385704, 111.78310...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>50</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>AvgPool</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Multi Margin</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>[{'loss_values': [3077.620689511299, 1735.1002...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>576 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_epochs activation_function  pooling n_conv_layers conv_out_channels  \\\n",
       "0         50                relu  MaxPool             1                16   \n",
       "1         50                relu  MaxPool             1                16   \n",
       "2         50                relu  MaxPool             1                16   \n",
       "3         50                relu  MaxPool             1                16   \n",
       "4         50                relu  MaxPool             1                16   \n",
       "..       ...                 ...      ...           ...               ...   \n",
       "571       50             sigmoid  AvgPool             2                16   \n",
       "572       50             sigmoid  AvgPool             2                16   \n",
       "573       50             sigmoid  AvgPool             2                16   \n",
       "574       50             sigmoid  AvgPool             2                16   \n",
       "575       50             sigmoid  AvgPool             2                16   \n",
       "\n",
       "    conv_kernel_size conv_padding n_layers batch_size learning_rate  \\\n",
       "0                  3            1        3         32         0.001   \n",
       "1                  3            1        3         32         0.001   \n",
       "2                  3            1        3         32         0.001   \n",
       "3                  3            1        3         32         0.001   \n",
       "4                  3            1        3         32         0.001   \n",
       "..               ...          ...      ...        ...           ...   \n",
       "571                3            1       15         64           0.1   \n",
       "572                3            1       15         64           0.1   \n",
       "573                3            1       15         64           0.1   \n",
       "574                3            1       15         64           0.1   \n",
       "575                3            1       15         64           0.1   \n",
       "\n",
       "     loss_function optimizer  \\\n",
       "0    Cross Entropy      ADAM   \n",
       "1    Cross Entropy       SGD   \n",
       "2    Cross Entropy   RMSprop   \n",
       "3     Multi Margin      ADAM   \n",
       "4     Multi Margin       SGD   \n",
       "..             ...       ...   \n",
       "571  Cross Entropy       SGD   \n",
       "572  Cross Entropy   RMSprop   \n",
       "573   Multi Margin      ADAM   \n",
       "574   Multi Margin       SGD   \n",
       "575   Multi Margin   RMSprop   \n",
       "\n",
       "                                               results  \n",
       "0    [{'loss_values': [231.8701878786087, 197.12700...  \n",
       "1    [{'loss_values': [239.3160616159439, 239.26000...  \n",
       "2    [{'loss_values': [5110.887897610664, 220.26268...  \n",
       "3    [{'loss_values': [86.5283233821392, 55.5496368...  \n",
       "4    [{'loss_values': [105.38043284416199, 105.3138...  \n",
       "..                                                 ...  \n",
       "571  [{'loss_values': [283.7384283542633, 244.37010...  \n",
       "572  [{'loss_values': [12106.481934070587, 6383.127...  \n",
       "573  [{'loss_values': [630.6281946897507, 447.19764...  \n",
       "574  [{'loss_values': [123.1793560385704, 111.78310...  \n",
       "575  [{'loss_values': [3077.620689511299, 1735.1002...  \n",
       "\n",
       "[576 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cnn = pd.read_json('results_cnn_1.json').T\n",
    "\n",
    "data_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_epochs</th>\n",
       "      <th>activation_function</th>\n",
       "      <th>pooling</th>\n",
       "      <th>n_conv_layers</th>\n",
       "      <th>conv_out_channels</th>\n",
       "      <th>conv_kernel_size</th>\n",
       "      <th>conv_padding</th>\n",
       "      <th>n_layers</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>recall_train</th>\n",
       "      <th>recall_test</th>\n",
       "      <th>averaged_recall_train</th>\n",
       "      <th>averaged_recall_test</th>\n",
       "      <th>precision_train</th>\n",
       "      <th>precision_test</th>\n",
       "      <th>averaged_precision_train</th>\n",
       "      <th>averaged_precision_test</th>\n",
       "      <th>f1_train_average</th>\n",
       "      <th>f1_test_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>MaxPool</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.8783461695378652, 0.7727700035245286, 0.804...</td>\n",
       "      <td>[0.5332652149018743, 0.4189186747709572, 0.436...</td>\n",
       "      <td>0.878731</td>\n",
       "      <td>0.587685</td>\n",
       "      <td>[0.8394743897181787, 0.8892373590590665, 0.857...</td>\n",
       "      <td>[0.5007983883078934, 0.5383121861435812, 0.491...</td>\n",
       "      <td>0.882657</td>\n",
       "      <td>0.588455</td>\n",
       "      <td>0.880689</td>\n",
       "      <td>0.588070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>MaxPool</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.18116847287235294, 0.6546719473864446, 0.00...</td>\n",
       "      <td>[0.17621491506095824, 0.6553112634440799, 0.00...</td>\n",
       "      <td>0.280925</td>\n",
       "      <td>0.279807</td>\n",
       "      <td>[0.23425496000797144, 0.23665133438647676, 0.1...</td>\n",
       "      <td>[0.18028448206330153, 0.23623675962678226, 0.0...</td>\n",
       "      <td>0.333323</td>\n",
       "      <td>0.311014</td>\n",
       "      <td>0.304889</td>\n",
       "      <td>0.294586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>MaxPool</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.8266388045034054, 0.8962256848774655, 0.902...</td>\n",
       "      <td>[0.47887338277403957, 0.5030780299028847, 0.54...</td>\n",
       "      <td>0.907138</td>\n",
       "      <td>0.608596</td>\n",
       "      <td>[0.9468313178098764, 0.8848190094839643, 0.835...</td>\n",
       "      <td>[0.6046804023160028, 0.547976948165036, 0.4816...</td>\n",
       "      <td>0.914522</td>\n",
       "      <td>0.616030</td>\n",
       "      <td>0.910815</td>\n",
       "      <td>0.612291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>MaxPool</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.889013033613435, 0.8476563638588956, 0.8321...</td>\n",
       "      <td>[0.5350818736054895, 0.4777231375858392, 0.430...</td>\n",
       "      <td>0.900022</td>\n",
       "      <td>0.590088</td>\n",
       "      <td>[0.8566739641952855, 0.8641449562608097, 0.916...</td>\n",
       "      <td>[0.5015345071595071, 0.5263866979086214, 0.514...</td>\n",
       "      <td>0.903775</td>\n",
       "      <td>0.589573</td>\n",
       "      <td>0.901895</td>\n",
       "      <td>0.589830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>MaxPool</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.12558665033680344, 0.5996485061511423, 0.0,...</td>\n",
       "      <td>[0.1215151515151515, 0.6, 0.0, 0.0, 0.00859595...</td>\n",
       "      <td>0.164875</td>\n",
       "      <td>0.162998</td>\n",
       "      <td>[0.05430857310628303, 0.09091184807202482, 0.0...</td>\n",
       "      <td>[0.046469622331691295, 0.08352534986527714, 0....</td>\n",
       "      <td>0.141456</td>\n",
       "      <td>0.105480</td>\n",
       "      <td>0.152270</td>\n",
       "      <td>0.128078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>50</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>AvgPool</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>64</td>\n",
       "      <td>0.100</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.8]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.8]</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.02872448979591837,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.02795918367346939,...</td>\n",
       "      <td>0.020569</td>\n",
       "      <td>0.019767</td>\n",
       "      <td>0.035960</td>\n",
       "      <td>0.034728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>50</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>AvgPool</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>64</td>\n",
       "      <td>0.100</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.2, 0.0, 0.4, 0.0, 0.0, 0.4, 0.0]</td>\n",
       "      <td>[0.2, 0.0, 0.4, 0.0, 0.0, 0.4, 0.0]</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>[0.02826530612244898, 0.0, 0.05709183673469388...</td>\n",
       "      <td>[0.029795918367346942, 0.0, 0.0573469387755102...</td>\n",
       "      <td>0.020277</td>\n",
       "      <td>0.020933</td>\n",
       "      <td>0.035513</td>\n",
       "      <td>0.036515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>50</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>AvgPool</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>64</td>\n",
       "      <td>0.100</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.2, 0.0, 0.2, 0.0, 0.6, 0.0, 0.0]</td>\n",
       "      <td>[0.2, 0.0, 0.2, 0.0, 0.6, 0.0, 0.0]</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>[0.02836734693877551, 0.0, 0.02933673469387755...</td>\n",
       "      <td>[0.02938775510204082, 0.0, 0.02551020408163265...</td>\n",
       "      <td>0.020488</td>\n",
       "      <td>0.020087</td>\n",
       "      <td>0.035837</td>\n",
       "      <td>0.035222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>50</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>AvgPool</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>64</td>\n",
       "      <td>0.100</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.2, 0.0, 0.2, 0.6]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.2, 0.0, 0.2, 0.6]</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0288265306122449, 0.0, 0.028...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.027551020408163263, 0.0, 0.0...</td>\n",
       "      <td>0.020649</td>\n",
       "      <td>0.019446</td>\n",
       "      <td>0.036082</td>\n",
       "      <td>0.034232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>50</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>AvgPool</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>64</td>\n",
       "      <td>0.100</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.6, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4]</td>\n",
       "      <td>[0.6, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4]</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>[0.08668367346938775, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.08183673469387755, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.020634</td>\n",
       "      <td>0.019504</td>\n",
       "      <td>0.036060</td>\n",
       "      <td>0.034323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>576 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     n_epochs activation_function  pooling  n_conv_layers  conv_out_channels  \\\n",
       "0          50                relu  MaxPool              1                 16   \n",
       "1          50                relu  MaxPool              1                 16   \n",
       "2          50                relu  MaxPool              1                 16   \n",
       "3          50                relu  MaxPool              1                 16   \n",
       "4          50                relu  MaxPool              1                 16   \n",
       "..        ...                 ...      ...            ...                ...   \n",
       "571        50             sigmoid  AvgPool              2                 16   \n",
       "572        50             sigmoid  AvgPool              2                 16   \n",
       "573        50             sigmoid  AvgPool              2                 16   \n",
       "574        50             sigmoid  AvgPool              2                 16   \n",
       "575        50             sigmoid  AvgPool              2                 16   \n",
       "\n",
       "     conv_kernel_size  conv_padding  n_layers  batch_size  learning_rate  ...  \\\n",
       "0                   3             1         3          32          0.001  ...   \n",
       "1                   3             1         3          32          0.001  ...   \n",
       "2                   3             1         3          32          0.001  ...   \n",
       "3                   3             1         3          32          0.001  ...   \n",
       "4                   3             1         3          32          0.001  ...   \n",
       "..                ...           ...       ...         ...            ...  ...   \n",
       "571                 3             1        15          64          0.100  ...   \n",
       "572                 3             1        15          64          0.100  ...   \n",
       "573                 3             1        15          64          0.100  ...   \n",
       "574                 3             1        15          64          0.100  ...   \n",
       "575                 3             1        15          64          0.100  ...   \n",
       "\n",
       "                                          recall_train  \\\n",
       "0    [0.8783461695378652, 0.7727700035245286, 0.804...   \n",
       "1    [0.18116847287235294, 0.6546719473864446, 0.00...   \n",
       "2    [0.8266388045034054, 0.8962256848774655, 0.902...   \n",
       "3    [0.889013033613435, 0.8476563638588956, 0.8321...   \n",
       "4    [0.12558665033680344, 0.5996485061511423, 0.0,...   \n",
       "..                                                 ...   \n",
       "571                [0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.8]   \n",
       "572                [0.2, 0.0, 0.4, 0.0, 0.0, 0.4, 0.0]   \n",
       "573                [0.2, 0.0, 0.2, 0.0, 0.6, 0.0, 0.0]   \n",
       "574                [0.0, 0.0, 0.0, 0.2, 0.0, 0.2, 0.6]   \n",
       "575                [0.6, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4]   \n",
       "\n",
       "                                           recall_test  averaged_recall_train  \\\n",
       "0    [0.5332652149018743, 0.4189186747709572, 0.436...               0.878731   \n",
       "1    [0.17621491506095824, 0.6553112634440799, 0.00...               0.280925   \n",
       "2    [0.47887338277403957, 0.5030780299028847, 0.54...               0.907138   \n",
       "3    [0.5350818736054895, 0.4777231375858392, 0.430...               0.900022   \n",
       "4    [0.1215151515151515, 0.6, 0.0, 0.0, 0.00859595...               0.164875   \n",
       "..                                                 ...                    ...   \n",
       "571                [0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.8]               0.142857   \n",
       "572                [0.2, 0.0, 0.4, 0.0, 0.0, 0.4, 0.0]               0.142857   \n",
       "573                [0.2, 0.0, 0.2, 0.0, 0.6, 0.0, 0.0]               0.142857   \n",
       "574                [0.0, 0.0, 0.0, 0.2, 0.0, 0.2, 0.6]               0.142857   \n",
       "575                [0.6, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4]               0.142857   \n",
       "\n",
       "     averaged_recall_test                                    precision_train  \\\n",
       "0                0.587685  [0.8394743897181787, 0.8892373590590665, 0.857...   \n",
       "1                0.279807  [0.23425496000797144, 0.23665133438647676, 0.1...   \n",
       "2                0.608596  [0.9468313178098764, 0.8848190094839643, 0.835...   \n",
       "3                0.590088  [0.8566739641952855, 0.8641449562608097, 0.916...   \n",
       "4                0.162998  [0.05430857310628303, 0.09091184807202482, 0.0...   \n",
       "..                    ...                                                ...   \n",
       "571              0.142857  [0.0, 0.0, 0.0, 0.0, 0.0, 0.02872448979591837,...   \n",
       "572              0.142857  [0.02826530612244898, 0.0, 0.05709183673469388...   \n",
       "573              0.142857  [0.02836734693877551, 0.0, 0.02933673469387755...   \n",
       "574              0.142857  [0.0, 0.0, 0.0, 0.0288265306122449, 0.0, 0.028...   \n",
       "575              0.142857  [0.08668367346938775, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "\n",
       "                                        precision_test  \\\n",
       "0    [0.5007983883078934, 0.5383121861435812, 0.491...   \n",
       "1    [0.18028448206330153, 0.23623675962678226, 0.0...   \n",
       "2    [0.6046804023160028, 0.547976948165036, 0.4816...   \n",
       "3    [0.5015345071595071, 0.5263866979086214, 0.514...   \n",
       "4    [0.046469622331691295, 0.08352534986527714, 0....   \n",
       "..                                                 ...   \n",
       "571  [0.0, 0.0, 0.0, 0.0, 0.0, 0.02795918367346939,...   \n",
       "572  [0.029795918367346942, 0.0, 0.0573469387755102...   \n",
       "573  [0.02938775510204082, 0.0, 0.02551020408163265...   \n",
       "574  [0.0, 0.0, 0.0, 0.027551020408163263, 0.0, 0.0...   \n",
       "575  [0.08183673469387755, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "\n",
       "    averaged_precision_train  averaged_precision_test  f1_train_average  \\\n",
       "0                   0.882657                 0.588455          0.880689   \n",
       "1                   0.333323                 0.311014          0.304889   \n",
       "2                   0.914522                 0.616030          0.910815   \n",
       "3                   0.903775                 0.589573          0.901895   \n",
       "4                   0.141456                 0.105480          0.152270   \n",
       "..                       ...                      ...               ...   \n",
       "571                 0.020569                 0.019767          0.035960   \n",
       "572                 0.020277                 0.020933          0.035513   \n",
       "573                 0.020488                 0.020087          0.035837   \n",
       "574                 0.020649                 0.019446          0.036082   \n",
       "575                 0.020634                 0.019504          0.036060   \n",
       "\n",
       "    f1_test_average  \n",
       "0          0.588070  \n",
       "1          0.294586  \n",
       "2          0.612291  \n",
       "3          0.589830  \n",
       "4          0.128078  \n",
       "..              ...  \n",
       "571        0.034728  \n",
       "572        0.036515  \n",
       "573        0.035222  \n",
       "574        0.034232  \n",
       "575        0.034323  \n",
       "\n",
       "[576 rows x 25 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_cnn = []\n",
    "\n",
    "for i, row in data_cnn.iterrows():\n",
    "\n",
    "    accuracy_fold_train = []\n",
    "    accuracy_fold_test = []\n",
    "\n",
    "    recall_fold_train = []\n",
    "    recall_fold_test = []\n",
    "\n",
    "    precision_fold_train = []\n",
    "    precision_fold_test = []\n",
    "\n",
    "    for iteration in row[\"results\"]:\n",
    "        \n",
    "        loss = iteration[\"loss_values\"]\n",
    "        conf_mat_train = np.array(iteration[\"confusion_matrix_train\"])\n",
    "        conf_mat_test = np.array(iteration[\"confusion_matrix_val\"])\n",
    "        \n",
    "        # Compute accuracy (7 classes)\n",
    "        total_train = conf_mat_train.sum()\n",
    "        total_test = conf_mat_test.sum()\n",
    "\n",
    "        accuracy_train = conf_mat_train.diagonal().sum() / total_train if total_train > 0 else 0\n",
    "        accuracy_test = conf_mat_test.diagonal().sum() / total_test if total_test > 0 else 0\n",
    "\n",
    "        # Compute recall and precision (per class)\n",
    "        recall_train = np.array([\n",
    "            conf_mat_train[i, i] / conf_mat_train[i, :].sum() if conf_mat_train[i, :].sum() > 0 else 0\n",
    "            for i in range(7)\n",
    "        ])\n",
    "        recall_test = np.array([\n",
    "            conf_mat_test[i, i] / conf_mat_test[i, :].sum() if conf_mat_test[i, :].sum() > 0 else 0\n",
    "            for i in range(7)\n",
    "        ])\n",
    "\n",
    "        precision_train = np.array([\n",
    "            conf_mat_train[i, i] / conf_mat_train[:, i].sum() if conf_mat_train[:, i].sum() > 0 else 0\n",
    "            for i in range(7)\n",
    "        ])\n",
    "        precision_test = np.array([\n",
    "            conf_mat_test[i, i] / conf_mat_test[:, i].sum() if conf_mat_test[:, i].sum() > 0 else 0\n",
    "            for i in range(7)\n",
    "        ])\n",
    "\n",
    "        accuracy_fold_train.append(accuracy_train)\n",
    "        accuracy_fold_test.append(accuracy_test)\n",
    "\n",
    "        recall_fold_train.append(recall_train)\n",
    "        recall_fold_test.append(recall_test)\n",
    "\n",
    "        precision_fold_train.append(precision_train)\n",
    "        precision_fold_test.append(precision_test)\n",
    "\n",
    "    # Compute mean across folds\n",
    "    accuracy_train = np.mean(accuracy_fold_train)\n",
    "    accuracy_test = np.mean(accuracy_fold_test)\n",
    "\n",
    "    recall_train = np.mean(recall_fold_train, axis=0)\n",
    "    recall_test = np.mean(recall_fold_test, axis=0)\n",
    "\n",
    "    precision_train = np.mean(precision_fold_train, axis=0)\n",
    "    precision_test = np.mean(precision_fold_test, axis=0)\n",
    "\n",
    "    average_recall_train = np.mean(recall_train)\n",
    "    average_recall_test = np.mean(recall_test)\n",
    "\n",
    "    average_precision_train = np.mean(precision_train)\n",
    "    average_precision_test = np.mean(precision_test)\n",
    "\n",
    "    f1_train_average = 2 * (average_precision_train * average_recall_train) / (average_precision_train + average_recall_train)\n",
    "    f1_test_average = 2 * (average_precision_test * average_recall_test) / (average_precision_test + average_recall_test) \n",
    "\n",
    "    row = row.drop(\"results\")\n",
    "    row_dict = row.to_dict()\n",
    "\n",
    "    metrics_cnn.append({\n",
    "        **row_dict,\n",
    "        \"iteration\": i,\n",
    "        \"accuracy_train\": accuracy_train,\n",
    "        \"accuracy_test\": accuracy_test,\n",
    "        \"recall_train\": recall_train.tolist(),  # Convert to list for DataFrame compatibility\n",
    "        \"recall_test\": recall_test.tolist(),\n",
    "        \"averaged_recall_train\": average_recall_train,\n",
    "        \"averaged_recall_test\": average_recall_test,\n",
    "        \"precision_train\": precision_train.tolist(),\n",
    "        \"precision_test\": precision_test.tolist(),\n",
    "        \"averaged_precision_train\": average_precision_train,\n",
    "        \"averaged_precision_test\": average_precision_test,\n",
    "        \"f1_train_average\": f1_train_average,\n",
    "        \"f1_test_average\": f1_test_average\n",
    "    })\n",
    "\n",
    "metrics_cnn = pd.DataFrame(metrics_cnn)\n",
    "metrics_cnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.6551872819161952), np.float64(0.973445018550672))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_f1_train = metrics_cnn[\"f1_train_average\"].max()\n",
    "max_f1_test = metrics_cnn[\"f1_test_average\"].max()\n",
    "\n",
    "max_f1_test, max_f1_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_epochs</th>\n",
       "      <th>activation_function</th>\n",
       "      <th>pooling</th>\n",
       "      <th>n_conv_layers</th>\n",
       "      <th>conv_out_channels</th>\n",
       "      <th>conv_kernel_size</th>\n",
       "      <th>conv_padding</th>\n",
       "      <th>n_layers</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>recall_train</th>\n",
       "      <th>recall_test</th>\n",
       "      <th>averaged_recall_train</th>\n",
       "      <th>averaged_recall_test</th>\n",
       "      <th>precision_train</th>\n",
       "      <th>precision_test</th>\n",
       "      <th>averaged_precision_train</th>\n",
       "      <th>averaged_precision_test</th>\n",
       "      <th>f1_train_average</th>\n",
       "      <th>f1_test_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>MaxPool</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.8659264478857184, 0.8888974790428635, 0.887...</td>\n",
       "      <td>[0.5892674918450334, 0.5782651828005414, 0.601...</td>\n",
       "      <td>0.887827</td>\n",
       "      <td>0.651995</td>\n",
       "      <td>[0.8860410350767609, 0.8516981988488196, 0.815...</td>\n",
       "      <td>[0.6093338004601769, 0.5575159327129008, 0.500...</td>\n",
       "      <td>0.89204</td>\n",
       "      <td>0.658411</td>\n",
       "      <td>0.889929</td>\n",
       "      <td>0.655187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_epochs activation_function  pooling  n_conv_layers  conv_out_channels  \\\n",
       "88        50                relu  MaxPool              2                 16   \n",
       "\n",
       "    conv_kernel_size  conv_padding  n_layers  batch_size  learning_rate  ...  \\\n",
       "88                 3             1         3          32            0.1  ...   \n",
       "\n",
       "                                         recall_train  \\\n",
       "88  [0.8659264478857184, 0.8888974790428635, 0.887...   \n",
       "\n",
       "                                          recall_test  averaged_recall_train  \\\n",
       "88  [0.5892674918450334, 0.5782651828005414, 0.601...               0.887827   \n",
       "\n",
       "    averaged_recall_test                                    precision_train  \\\n",
       "88              0.651995  [0.8860410350767609, 0.8516981988488196, 0.815...   \n",
       "\n",
       "                                       precision_test  \\\n",
       "88  [0.6093338004601769, 0.5575159327129008, 0.500...   \n",
       "\n",
       "   averaged_precision_train  averaged_precision_test  f1_train_average  \\\n",
       "88                  0.89204                 0.658411          0.889929   \n",
       "\n",
       "   f1_test_average  \n",
       "88        0.655187  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_f1_test_df = metrics_cnn[metrics_cnn[\"f1_test_average\"] == max_f1_test]\n",
    "\n",
    "max_f1_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[105.60230594873428,\n",
       " 105.38202220201492,\n",
       " 104.90448349714279,\n",
       " 102.3214111328125,\n",
       " 89.94781196117401,\n",
       " 81.43068143725395,\n",
       " 74.76438850164413,\n",
       " 67.34454053640366,\n",
       " 60.36889824271202,\n",
       " 55.56464609503746,\n",
       " 51.46674019098282,\n",
       " 48.993880569934845,\n",
       " 47.120235577225685,\n",
       " 44.87460754811764,\n",
       " 43.49683155119419,\n",
       " 42.350684747099876,\n",
       " 40.86074589192867,\n",
       " 39.56651718914509,\n",
       " 38.81584033370018,\n",
       " 37.11140884459019,\n",
       " 36.02084735035896,\n",
       " 34.88637848198414,\n",
       " 33.67324863374233,\n",
       " 32.45380114018917,\n",
       " 31.064642071723938,\n",
       " 30.56198740005493,\n",
       " 28.983667820692062,\n",
       " 28.17554910480976,\n",
       " 27.343372851610184,\n",
       " 26.19862338155508,\n",
       " 24.825267866253853,\n",
       " 24.400974564254284,\n",
       " 22.88215731829405,\n",
       " 22.035077683627605,\n",
       " 21.16768527030945,\n",
       " 20.217142581939697,\n",
       " 18.832558520138264,\n",
       " 17.985417790710926,\n",
       " 16.46894733607769,\n",
       " 15.597387813031673,\n",
       " 15.853816285729408,\n",
       " 13.680530652403831,\n",
       " 13.103746600449085,\n",
       " 11.859712425619364,\n",
       " 11.207306940108538,\n",
       " 10.380613692104816,\n",
       " 9.343946492299438,\n",
       " 8.996293969452381,\n",
       " 8.32403757236898,\n",
       " 7.961157085373998]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_max_f1_test = data_cnn.iloc[88][\"results\"][0][\"loss_values\"]\n",
    "\n",
    "loss_max_f1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9832842071171564, 0.9587692749794524, 0.9639390937984315, 0.98351714357373, 0.9749707639197933, 0.9500338639889276, 0.9974595977211951]]\n",
      "[[0.6246096953822946, 0.48755394501861193, 0.5540707195411665, 0.8190502524732276, 0.5339011541153807, 0.612316025029182, 0.9467718411497248]]\n",
      "[[0.970402620114605, 0.9835636720718766, 0.9641945930944388, 0.9817429678643872, 0.9553281812770139, 0.9729931799120685, 0.9880324467623083]]\n",
      "[[0.5971752925329048, 0.5986630892810394, 0.52509215591249, 0.7778723065335569, 0.5255409258048653, 0.6705476382852498, 0.8836107412794512]]\n"
     ]
    }
   ],
   "source": [
    "max_f1_train_df = metrics_cnn[metrics_cnn[\"f1_train_average\"] == max_f1_train]\n",
    "\n",
    "print(max_f1_train_df[\"recall_train\"].tolist())\n",
    "print(max_f1_train_df[\"recall_test\"].tolist())\n",
    "print(max_f1_train_df[\"precision_train\"].tolist())\n",
    "print(max_f1_train_df[\"precision_test\"].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss_values</th>\n",
       "      <th>confusion_matrix_train</th>\n",
       "      <th>confusion_matrix_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>{'activation_function': 'relu', 'pooling': MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), 'n_conv_layers': 1, 'conv_out_channels': 16, 'conv_kernel_size': 3, 'conv_padding': 1, 'n_layers': 3, 'batch_size': 32, 'learning_rate': 0.001, 'n_epochs': 50, 'loss_function': CrossEntropyLoss(), 'optimizer': 'ADAM'}</th>\n",
       "      <td>[226.924173027277, 199.65306049585342, 187.177...</td>\n",
       "      <td>[[171, 7, 27, 0, 6, 17, 0], [10, 274, 18, 2, 2...</td>\n",
       "      <td>[[8, 6, 10, 0, 2, 7, 0], [7, 8, 13, 2, 2, 17, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'activation_function': 'relu', 'pooling': MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), 'n_conv_layers': 1, 'conv_out_channels': 16, 'conv_kernel_size': 3, 'conv_padding': 1, 'n_layers': 3, 'batch_size': 32, 'learning_rate': 0.001, 'n_epochs': 50, 'loss_function': CrossEntropyLoss(), 'optimizer': 'SGD'}</th>\n",
       "      <td>[342.77393037080765, 257.20066130161285, 251.5...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 228, 0], [0, 0, 0, 0, 0, 359,...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 33, 0], [0, 0, 0, 0, 0, 52, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'activation_function': 'relu', 'pooling': MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), 'n_conv_layers': 1, 'conv_out_channels': 16, 'conv_kernel_size': 3, 'conv_padding': 1, 'n_layers': 3, 'batch_size': 32, 'learning_rate': 0.001, 'n_epochs': 50, 'loss_function': CrossEntropyLoss(), 'optimizer': 'RMSprop'}</th>\n",
       "      <td>[5131.045579850674, 214.05115136504173, 206.67...</td>\n",
       "      <td>[[103, 9, 62, 0, 40, 13, 1], [69, 134, 56, 0, ...</td>\n",
       "      <td>[[8, 1, 12, 0, 10, 2, 0], [10, 10, 10, 0, 12, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'activation_function': 'relu', 'pooling': MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), 'n_conv_layers': 1, 'conv_out_channels': 16, 'conv_kernel_size': 3, 'conv_padding': 1, 'n_layers': 3, 'batch_size': 32, 'learning_rate': 0.001, 'n_epochs': 50, 'loss_function': MultiMarginLoss(), 'optimizer': 'ADAM'}</th>\n",
       "      <td>[58.51678302884102, 50.87195182964206, 48.7272...</td>\n",
       "      <td>[[171, 3, 43, 2, 1, 7, 1], [6, 295, 38, 3, 1, ...</td>\n",
       "      <td>[[7, 5, 10, 2, 4, 5, 0], [4, 15, 15, 0, 2, 15,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'activation_function': 'relu', 'pooling': MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), 'n_conv_layers': 1, 'conv_out_channels': 16, 'conv_kernel_size': 3, 'conv_padding': 1, 'n_layers': 3, 'batch_size': 32, 'learning_rate': 0.001, 'n_epochs': 50, 'loss_function': MultiMarginLoss(), 'optimizer': 'SGD'}</th>\n",
       "      <td>[107.61979326605797, 65.31336613744497, 58.118...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 228, 0], [0, 0, 0, 0, 0, 359,...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 33, 0], [0, 0, 0, 0, 0, 52, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'activation_function': 'sigmoid', 'pooling': AvgPool2d(kernel_size=2, stride=2, padding=0), 'n_conv_layers': 2, 'conv_out_channels': 16, 'conv_kernel_size': 3, 'conv_padding': 1, 'n_layers': 15, 'batch_size': 64, 'learning_rate': 0.1, 'n_epochs': 50, 'loss_function': CrossEntropyLoss(), 'optimizer': 'SGD'}</th>\n",
       "      <td>[295.71725058555603, 252.1200835108757, 250.53...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 228, 0], [0, 0, 0, 0, 0, 359,...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 33, 0], [0, 0, 0, 0, 0, 52, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'activation_function': 'sigmoid', 'pooling': AvgPool2d(kernel_size=2, stride=2, padding=0), 'n_conv_layers': 2, 'conv_out_channels': 16, 'conv_kernel_size': 3, 'conv_padding': 1, 'n_layers': 15, 'batch_size': 64, 'learning_rate': 0.1, 'n_epochs': 50, 'loss_function': CrossEntropyLoss(), 'optimizer': 'RMSprop'}</th>\n",
       "      <td>[11401.522626161575, 7163.660587310791, 7237.0...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 228, 0], [0, 0, 0, 0, 0, 359,...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 33, 0], [0, 0, 0, 0, 0, 52, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'activation_function': 'sigmoid', 'pooling': AvgPool2d(kernel_size=2, stride=2, padding=0), 'n_conv_layers': 2, 'conv_out_channels': 16, 'conv_kernel_size': 3, 'conv_padding': 1, 'n_layers': 15, 'batch_size': 64, 'learning_rate': 0.1, 'n_epochs': 50, 'loss_function': MultiMarginLoss(), 'optimizer': 'ADAM'}</th>\n",
       "      <td>[621.0176554173231, 582.4375709891319, 533.248...</td>\n",
       "      <td>[[0, 0, 228, 0, 0, 0, 0], [0, 0, 359, 0, 0, 0,...</td>\n",
       "      <td>[[0, 0, 33, 0, 0, 0, 0], [0, 0, 52, 0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'activation_function': 'sigmoid', 'pooling': AvgPool2d(kernel_size=2, stride=2, padding=0), 'n_conv_layers': 2, 'conv_out_channels': 16, 'conv_kernel_size': 3, 'conv_padding': 1, 'n_layers': 15, 'batch_size': 64, 'learning_rate': 0.1, 'n_epochs': 50, 'loss_function': MultiMarginLoss(), 'optimizer': 'SGD'}</th>\n",
       "      <td>[83.25152276456356, 68.77613618224859, 63.5174...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 228, 0], [0, 0, 0, 0, 0, 359,...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 33, 0], [0, 0, 0, 0, 0, 52, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'activation_function': 'sigmoid', 'pooling': AvgPool2d(kernel_size=2, stride=2, padding=0), 'n_conv_layers': 2, 'conv_out_channels': 16, 'conv_kernel_size': 3, 'conv_padding': 1, 'n_layers': 15, 'batch_size': 64, 'learning_rate': 0.1, 'n_epochs': 50, 'loss_function': MultiMarginLoss(), 'optimizer': 'RMSprop'}</th>\n",
       "      <td>[2296.831926703453, 1541.4792679548264, 1536.5...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 228, 0], [0, 0, 0, 0, 0, 359,...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 33, 0], [0, 0, 0, 0, 0, 52, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>576 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                          loss_values  \\\n",
       "{'activation_function': 'relu', 'pooling': MaxP...  [226.924173027277, 199.65306049585342, 187.177...   \n",
       "{'activation_function': 'relu', 'pooling': MaxP...  [342.77393037080765, 257.20066130161285, 251.5...   \n",
       "{'activation_function': 'relu', 'pooling': MaxP...  [5131.045579850674, 214.05115136504173, 206.67...   \n",
       "{'activation_function': 'relu', 'pooling': MaxP...  [58.51678302884102, 50.87195182964206, 48.7272...   \n",
       "{'activation_function': 'relu', 'pooling': MaxP...  [107.61979326605797, 65.31336613744497, 58.118...   \n",
       "...                                                                                               ...   \n",
       "{'activation_function': 'sigmoid', 'pooling': A...  [295.71725058555603, 252.1200835108757, 250.53...   \n",
       "{'activation_function': 'sigmoid', 'pooling': A...  [11401.522626161575, 7163.660587310791, 7237.0...   \n",
       "{'activation_function': 'sigmoid', 'pooling': A...  [621.0176554173231, 582.4375709891319, 533.248...   \n",
       "{'activation_function': 'sigmoid', 'pooling': A...  [83.25152276456356, 68.77613618224859, 63.5174...   \n",
       "{'activation_function': 'sigmoid', 'pooling': A...  [2296.831926703453, 1541.4792679548264, 1536.5...   \n",
       "\n",
       "                                                                               confusion_matrix_train  \\\n",
       "{'activation_function': 'relu', 'pooling': MaxP...  [[171, 7, 27, 0, 6, 17, 0], [10, 274, 18, 2, 2...   \n",
       "{'activation_function': 'relu', 'pooling': MaxP...  [[0, 0, 0, 0, 0, 228, 0], [0, 0, 0, 0, 0, 359,...   \n",
       "{'activation_function': 'relu', 'pooling': MaxP...  [[103, 9, 62, 0, 40, 13, 1], [69, 134, 56, 0, ...   \n",
       "{'activation_function': 'relu', 'pooling': MaxP...  [[171, 3, 43, 2, 1, 7, 1], [6, 295, 38, 3, 1, ...   \n",
       "{'activation_function': 'relu', 'pooling': MaxP...  [[0, 0, 0, 0, 0, 228, 0], [0, 0, 0, 0, 0, 359,...   \n",
       "...                                                                                               ...   \n",
       "{'activation_function': 'sigmoid', 'pooling': A...  [[0, 0, 0, 0, 0, 228, 0], [0, 0, 0, 0, 0, 359,...   \n",
       "{'activation_function': 'sigmoid', 'pooling': A...  [[0, 0, 0, 0, 0, 228, 0], [0, 0, 0, 0, 0, 359,...   \n",
       "{'activation_function': 'sigmoid', 'pooling': A...  [[0, 0, 228, 0, 0, 0, 0], [0, 0, 359, 0, 0, 0,...   \n",
       "{'activation_function': 'sigmoid', 'pooling': A...  [[0, 0, 0, 0, 0, 228, 0], [0, 0, 0, 0, 0, 359,...   \n",
       "{'activation_function': 'sigmoid', 'pooling': A...  [[0, 0, 0, 0, 0, 228, 0], [0, 0, 0, 0, 0, 359,...   \n",
       "\n",
       "                                                                                 confusion_matrix_val  \n",
       "{'activation_function': 'relu', 'pooling': MaxP...  [[8, 6, 10, 0, 2, 7, 0], [7, 8, 13, 2, 2, 17, ...  \n",
       "{'activation_function': 'relu', 'pooling': MaxP...  [[0, 0, 0, 0, 0, 33, 0], [0, 0, 0, 0, 0, 52, 0...  \n",
       "{'activation_function': 'relu', 'pooling': MaxP...  [[8, 1, 12, 0, 10, 2, 0], [10, 10, 10, 0, 12, ...  \n",
       "{'activation_function': 'relu', 'pooling': MaxP...  [[7, 5, 10, 2, 4, 5, 0], [4, 15, 15, 0, 2, 15,...  \n",
       "{'activation_function': 'relu', 'pooling': MaxP...  [[0, 0, 0, 0, 0, 33, 0], [0, 0, 0, 0, 0, 52, 0...  \n",
       "...                                                                                               ...  \n",
       "{'activation_function': 'sigmoid', 'pooling': A...  [[0, 0, 0, 0, 0, 33, 0], [0, 0, 0, 0, 0, 52, 0...  \n",
       "{'activation_function': 'sigmoid', 'pooling': A...  [[0, 0, 0, 0, 0, 33, 0], [0, 0, 0, 0, 0, 52, 0...  \n",
       "{'activation_function': 'sigmoid', 'pooling': A...  [[0, 0, 33, 0, 0, 0, 0], [0, 0, 52, 0, 0, 0, 0...  \n",
       "{'activation_function': 'sigmoid', 'pooling': A...  [[0, 0, 0, 0, 0, 33, 0], [0, 0, 0, 0, 0, 52, 0...  \n",
       "{'activation_function': 'sigmoid', 'pooling': A...  [[0, 0, 0, 0, 0, 33, 0], [0, 0, 0, 0, 0, 52, 0...  \n",
       "\n",
       "[576 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_no_aug_cnn = pd.read_json('../results_original/results_cnn.json').T\n",
    "\n",
    "data_no_aug_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>recall_train</th>\n",
       "      <th>recall_test</th>\n",
       "      <th>averaged_recall_train</th>\n",
       "      <th>averaged_recall_test</th>\n",
       "      <th>precision_train</th>\n",
       "      <th>precision_test</th>\n",
       "      <th>averaged_precision_train</th>\n",
       "      <th>averaged_precision_test</th>\n",
       "      <th>f1_score_train</th>\n",
       "      <th>f1_score_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.941915</td>\n",
       "      <td>0.707876</td>\n",
       "      <td>[0.75, 0.7632311977715878, 0.8764629388816645,...</td>\n",
       "      <td>[0.24242424242424243, 0.15384615384615385, 0.3...</td>\n",
       "      <td>0.933437</td>\n",
       "      <td>0.360397</td>\n",
       "      <td>[0.9095744680851063, 0.958041958041958, 0.8915...</td>\n",
       "      <td>[0.34782608695652173, 0.26666666666666666, 0.4...</td>\n",
       "      <td>0.933437</td>\n",
       "      <td>0.416423</td>\n",
       "      <td>0.884274</td>\n",
       "      <td>0.386390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.669759</td>\n",
       "      <td>0.668993</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>0.095680</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.6697588126159555, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.6689930209371885, ...</td>\n",
       "      <td>0.095680</td>\n",
       "      <td>0.095570</td>\n",
       "      <td>0.114603</td>\n",
       "      <td>0.114525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.838019</td>\n",
       "      <td>0.682951</td>\n",
       "      <td>[0.4517543859649123, 0.3732590529247911, 0.806...</td>\n",
       "      <td>[0.24242424242424243, 0.19230769230769232, 0.4...</td>\n",
       "      <td>0.774206</td>\n",
       "      <td>0.370689</td>\n",
       "      <td>[0.49282296650717705, 0.7362637362637363, 0.61...</td>\n",
       "      <td>[0.27586206896551724, 0.4, 0.35570469798657717...</td>\n",
       "      <td>0.774206</td>\n",
       "      <td>0.440042</td>\n",
       "      <td>0.678539</td>\n",
       "      <td>0.402399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.934637</td>\n",
       "      <td>0.713858</td>\n",
       "      <td>[0.75, 0.8217270194986073, 0.893368010403121, ...</td>\n",
       "      <td>[0.21212121212121213, 0.28846153846153844, 0.4...</td>\n",
       "      <td>0.908192</td>\n",
       "      <td>0.409683</td>\n",
       "      <td>[0.9293478260869565, 0.913312693498452, 0.8149...</td>\n",
       "      <td>[0.35, 0.38461538461538464, 0.4196428571428571...</td>\n",
       "      <td>0.908192</td>\n",
       "      <td>0.456995</td>\n",
       "      <td>0.879815</td>\n",
       "      <td>0.432048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.669759</td>\n",
       "      <td>0.668993</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>0.095680</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.6697588126159555, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.6689930209371885, ...</td>\n",
       "      <td>0.095680</td>\n",
       "      <td>0.095570</td>\n",
       "      <td>0.114603</td>\n",
       "      <td>0.114525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>571</td>\n",
       "      <td>0.669759</td>\n",
       "      <td>0.668993</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>0.095680</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.6697588126159555, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.6689930209371885, ...</td>\n",
       "      <td>0.095680</td>\n",
       "      <td>0.095570</td>\n",
       "      <td>0.114603</td>\n",
       "      <td>0.114525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>572</td>\n",
       "      <td>0.669759</td>\n",
       "      <td>0.668993</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>0.095680</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.6697588126159555, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.6689930209371885, ...</td>\n",
       "      <td>0.095680</td>\n",
       "      <td>0.095570</td>\n",
       "      <td>0.114603</td>\n",
       "      <td>0.114525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>573</td>\n",
       "      <td>0.109747</td>\n",
       "      <td>0.109671</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0.015678</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>[0.0, 0.0, 0.10974739546168118, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.0, 0.0, 0.10967098703888335, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.015678</td>\n",
       "      <td>0.015667</td>\n",
       "      <td>0.028255</td>\n",
       "      <td>0.028238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>574</td>\n",
       "      <td>0.669759</td>\n",
       "      <td>0.668993</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>0.095680</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.6697588126159555, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.6689930209371885, ...</td>\n",
       "      <td>0.095680</td>\n",
       "      <td>0.095570</td>\n",
       "      <td>0.114603</td>\n",
       "      <td>0.114525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>575</td>\n",
       "      <td>0.669759</td>\n",
       "      <td>0.668993</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>0.095680</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.6697588126159555, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.6689930209371885, ...</td>\n",
       "      <td>0.095680</td>\n",
       "      <td>0.095570</td>\n",
       "      <td>0.114603</td>\n",
       "      <td>0.114525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>576 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     iteration  accuracy_train  accuracy_test  \\\n",
       "0            0        0.941915       0.707876   \n",
       "1            1        0.669759       0.668993   \n",
       "2            2        0.838019       0.682951   \n",
       "3            3        0.934637       0.713858   \n",
       "4            4        0.669759       0.668993   \n",
       "..         ...             ...            ...   \n",
       "571        571        0.669759       0.668993   \n",
       "572        572        0.669759       0.668993   \n",
       "573        573        0.109747       0.109671   \n",
       "574        574        0.669759       0.668993   \n",
       "575        575        0.669759       0.668993   \n",
       "\n",
       "                                          recall_train  \\\n",
       "0    [0.75, 0.7632311977715878, 0.8764629388816645,...   \n",
       "1                  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]   \n",
       "2    [0.4517543859649123, 0.3732590529247911, 0.806...   \n",
       "3    [0.75, 0.8217270194986073, 0.893368010403121, ...   \n",
       "4                  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]   \n",
       "..                                                 ...   \n",
       "571                [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]   \n",
       "572                [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]   \n",
       "573                [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "574                [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]   \n",
       "575                [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]   \n",
       "\n",
       "                                           recall_test  averaged_recall_train  \\\n",
       "0    [0.24242424242424243, 0.15384615384615385, 0.3...               0.933437   \n",
       "1                  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]               0.095680   \n",
       "2    [0.24242424242424243, 0.19230769230769232, 0.4...               0.774206   \n",
       "3    [0.21212121212121213, 0.28846153846153844, 0.4...               0.908192   \n",
       "4                  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]               0.095680   \n",
       "..                                                 ...                    ...   \n",
       "571                [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]               0.095680   \n",
       "572                [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]               0.095680   \n",
       "573                [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]               0.015678   \n",
       "574                [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]               0.095680   \n",
       "575                [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]               0.095680   \n",
       "\n",
       "     averaged_recall_test                                    precision_train  \\\n",
       "0                0.360397  [0.9095744680851063, 0.958041958041958, 0.8915...   \n",
       "1                0.142857  [0.0, 0.0, 0.0, 0.0, 0.0, 0.6697588126159555, ...   \n",
       "2                0.370689  [0.49282296650717705, 0.7362637362637363, 0.61...   \n",
       "3                0.409683  [0.9293478260869565, 0.913312693498452, 0.8149...   \n",
       "4                0.142857  [0.0, 0.0, 0.0, 0.0, 0.0, 0.6697588126159555, ...   \n",
       "..                    ...                                                ...   \n",
       "571              0.142857  [0.0, 0.0, 0.0, 0.0, 0.0, 0.6697588126159555, ...   \n",
       "572              0.142857  [0.0, 0.0, 0.0, 0.0, 0.0, 0.6697588126159555, ...   \n",
       "573              0.142857  [0.0, 0.0, 0.10974739546168118, 0.0, 0.0, 0.0,...   \n",
       "574              0.142857  [0.0, 0.0, 0.0, 0.0, 0.0, 0.6697588126159555, ...   \n",
       "575              0.142857  [0.0, 0.0, 0.0, 0.0, 0.0, 0.6697588126159555, ...   \n",
       "\n",
       "                                        precision_test  \\\n",
       "0    [0.34782608695652173, 0.26666666666666666, 0.4...   \n",
       "1    [0.0, 0.0, 0.0, 0.0, 0.0, 0.6689930209371885, ...   \n",
       "2    [0.27586206896551724, 0.4, 0.35570469798657717...   \n",
       "3    [0.35, 0.38461538461538464, 0.4196428571428571...   \n",
       "4    [0.0, 0.0, 0.0, 0.0, 0.0, 0.6689930209371885, ...   \n",
       "..                                                 ...   \n",
       "571  [0.0, 0.0, 0.0, 0.0, 0.0, 0.6689930209371885, ...   \n",
       "572  [0.0, 0.0, 0.0, 0.0, 0.0, 0.6689930209371885, ...   \n",
       "573  [0.0, 0.0, 0.10967098703888335, 0.0, 0.0, 0.0,...   \n",
       "574  [0.0, 0.0, 0.0, 0.0, 0.0, 0.6689930209371885, ...   \n",
       "575  [0.0, 0.0, 0.0, 0.0, 0.0, 0.6689930209371885, ...   \n",
       "\n",
       "     averaged_precision_train  averaged_precision_test  f1_score_train  \\\n",
       "0                    0.933437                 0.416423        0.884274   \n",
       "1                    0.095680                 0.095570        0.114603   \n",
       "2                    0.774206                 0.440042        0.678539   \n",
       "3                    0.908192                 0.456995        0.879815   \n",
       "4                    0.095680                 0.095570        0.114603   \n",
       "..                        ...                      ...             ...   \n",
       "571                  0.095680                 0.095570        0.114603   \n",
       "572                  0.095680                 0.095570        0.114603   \n",
       "573                  0.015678                 0.015667        0.028255   \n",
       "574                  0.095680                 0.095570        0.114603   \n",
       "575                  0.095680                 0.095570        0.114603   \n",
       "\n",
       "     f1_score_test  \n",
       "0         0.386390  \n",
       "1         0.114525  \n",
       "2         0.402399  \n",
       "3         0.432048  \n",
       "4         0.114525  \n",
       "..             ...  \n",
       "571       0.114525  \n",
       "572       0.114525  \n",
       "573       0.028238  \n",
       "574       0.114525  \n",
       "575       0.114525  \n",
       "\n",
       "[576 rows x 13 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "results_all = []\n",
    "j = 0\n",
    "\n",
    "for i, row in data_no_aug_cnn.iterrows():\n",
    "\n",
    "    conf_mat_train = np.array(row[\"confusion_matrix_train\"])\n",
    "    conf_mat_test = np.array(row[\"confusion_matrix_val\"])\n",
    "\n",
    "    total_train = conf_mat_train.sum()\n",
    "    total_test = conf_mat_test.sum()\n",
    "\n",
    "    accuracy_train = conf_mat_train.diagonal().sum() / total_train if total_train > 0 else 0\n",
    "    accuracy_test = conf_mat_test.diagonal().sum() / total_test if total_test > 0 else 0\n",
    "\n",
    "    # Compute recall and precision (per class)\n",
    "    recall_train = np.array([\n",
    "        conf_mat_train[i, i] / conf_mat_train[i, :].sum() if conf_mat_train[i, :].sum() > 0 else 0\n",
    "        for i in range(7)\n",
    "    ])\n",
    "    recall_test = np.array([\n",
    "        conf_mat_test[i, i] / conf_mat_test[i, :].sum() if conf_mat_test[i, :].sum() > 0 else 0\n",
    "        for i in range(7)\n",
    "    ])\n",
    "\n",
    "    precision_train = np.array([\n",
    "        conf_mat_train[i, i] / conf_mat_train[:, i].sum() if conf_mat_train[:, i].sum() > 0 else 0\n",
    "        for i in range(7)\n",
    "    ])\n",
    "    precision_test = np.array([\n",
    "        conf_mat_test[i, i] / conf_mat_test[:, i].sum() if conf_mat_test[:, i].sum() > 0 else 0\n",
    "        for i in range(7)\n",
    "    ])\n",
    "\n",
    "    average_recall_train = np.mean(recall_train)\n",
    "    average_precision_train = np.mean(precision_train)\n",
    "\n",
    "    average_recall_test = np.mean(recall_test)\n",
    "    average_precision_test = np.mean(precision_test)\n",
    "\n",
    "    f1_score_train = 2 * (average_precision_train * average_recall_train) / (average_precision_train + average_recall_train)\n",
    "    f1_score_test  = 2 * (average_precision_test  * average_recall_test)  / (average_precision_test  + average_recall_test)\n",
    "\n",
    "    results_all.append({\n",
    "        \"iteration\": j,\n",
    "        \"accuracy_train\": accuracy_train,\n",
    "        \"accuracy_test\": accuracy_test,\n",
    "        \"recall_train\": recall_train.tolist(),\n",
    "        \"recall_test\": recall_test.tolist(),\n",
    "        \"averaged_recall_train\": average_precision_train,\n",
    "        \"averaged_recall_test\": average_recall_test,\n",
    "        \"precision_train\": precision_train,\n",
    "        \"precision_test\": precision_test,\n",
    "        \"averaged_precision_train\": average_precision_train,\n",
    "        \"averaged_precision_test\": average_precision_test,\n",
    "        \"f1_score_train\": f1_score_train,\n",
    "        \"f1_score_test\": f1_score_test\n",
    "    })\n",
    "    \n",
    "    j += 1\n",
    "\n",
    "metrics_cnn_no_aug = pd.DataFrame(results_all)\n",
    "metrics_cnn_no_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5139272775997877 0.9076493479959407\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>recall_train</th>\n",
       "      <th>recall_test</th>\n",
       "      <th>averaged_recall_train</th>\n",
       "      <th>averaged_recall_test</th>\n",
       "      <th>precision_train</th>\n",
       "      <th>precision_test</th>\n",
       "      <th>averaged_precision_train</th>\n",
       "      <th>averaged_precision_test</th>\n",
       "      <th>f1_score_train</th>\n",
       "      <th>f1_score_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>74</td>\n",
       "      <td>0.942914</td>\n",
       "      <td>0.749751</td>\n",
       "      <td>[0.8859649122807017, 0.8161559888579387, 0.825...</td>\n",
       "      <td>[0.30303030303030304, 0.4230769230769231, 0.45...</td>\n",
       "      <td>0.932306</td>\n",
       "      <td>0.465731</td>\n",
       "      <td>[0.926605504587156, 0.9606557377049181, 0.9283...</td>\n",
       "      <td>[0.5263157894736842, 0.55, 0.5376344086021505,...</td>\n",
       "      <td>0.932306</td>\n",
       "      <td>0.57325</td>\n",
       "      <td>0.902291</td>\n",
       "      <td>0.513927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    iteration  accuracy_train  accuracy_test  \\\n",
       "74         74        0.942914       0.749751   \n",
       "\n",
       "                                         recall_train  \\\n",
       "74  [0.8859649122807017, 0.8161559888579387, 0.825...   \n",
       "\n",
       "                                          recall_test  averaged_recall_train  \\\n",
       "74  [0.30303030303030304, 0.4230769230769231, 0.45...               0.932306   \n",
       "\n",
       "    averaged_recall_test                                    precision_train  \\\n",
       "74              0.465731  [0.926605504587156, 0.9606557377049181, 0.9283...   \n",
       "\n",
       "                                       precision_test  \\\n",
       "74  [0.5263157894736842, 0.55, 0.5376344086021505,...   \n",
       "\n",
       "    averaged_precision_train  averaged_precision_test  f1_score_train  \\\n",
       "74                  0.932306                  0.57325        0.902291   \n",
       "\n",
       "    f1_score_test  \n",
       "74       0.513927  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_f1_train = metrics_cnn_no_aug[\"f1_score_train\"].max()\n",
    "max_f1_test = metrics_cnn_no_aug[\"f1_score_test\"].max()\n",
    "\n",
    "print(max_f1_test, max_f1_train)\n",
    "\n",
    "max_f1_test_df = metrics_cnn_no_aug[metrics_cnn_no_aug[\"f1_score_test\"] == max_f1_test]\n",
    "\n",
    "max_f1_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aca",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
